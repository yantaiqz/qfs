import streamlit as st
import google.generativeai as genai
import requests
import json
import datetime
import os
import time

# -------------------------------------------------------------
# --- 0. é¡µé¢é…ç½®å’Œ CSS æ³¨å…¥ (Kimié£æ ¼ + æ— é¡¶éƒ¨ç©ºç™½ + ä¸Šä¸‹æ’åˆ—) ---
# -------------------------------------------------------------

st.set_page_config(
    page_title="å¾·å›½è´¢ç¨ä¸“å®¶QFS", 
    page_icon="ğŸ‡©ğŸ‡ª", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Kimié£æ ¼ CSS æ³¨å…¥ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰
st.markdown("""
<style>
    /* 1. å½»åº•ç§»é™¤æ‰€æœ‰é»˜è®¤ç©ºç™½å’Œè¾¹è· */
    html, body, [data-testid="stAppViewContainer"], [data-testid="stMain"] {
        padding: 0 !important;
        margin: 0 !important;
        background-color: #f5f7fa !important;
    }
    
    /* 2. éšè—æ‰€æœ‰é»˜è®¤å…ƒç´  */
    header, [data-testid="stSidebar"], footer, .stDeployButton, [data-testid="stToolbar"],
    [data-testid="stDecoration"], [data-testid="stStatusWidget"] {
        display: none !important;
    }
    
    /* 3. å…¨å±€æ ·å¼ï¼ˆKimié£æ ¼ï¼‰ */
    .stApp {
        background-color: #f5f7fa !important;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
        padding: 0 !important;
        margin: 0 !important;
        max-width: 100% !important;
    }

    /* 4. ä¸»å®¹å™¨ï¼ˆKimié£æ ¼å±…ä¸­+çª„è¾¹è·ï¼‰ */
    .main-container {
        max-width: 900px !important;
        width: 100% !important;
        margin: 0 auto !important;
        padding: 16px 24px 80px 24px !important; /* åº•éƒ¨ç•™ç©ºç»™è¾“å…¥æ¡† */
        box-sizing: border-box !important;
    }

    /* 5. æ ‡é¢˜åŒºåŸŸï¼ˆKimié£æ ¼ï¼‰ */
    .page-title {
        font-size: 2rem !important;
        font-weight: 600 !important;
        color: #2d3748 !important;
        margin: 8px 0 12px 0 !important;
        line-height: 1.3 !important;
    }
    .subtitle {
        font-size: 0.95rem !important;
        color: #718096 !important;
        margin: 0 0 24px 0 !important;
        font-weight: 400 !important;
        line-height: 1.5 !important;
    }

    /* 6. èŠå¤©æ¶ˆæ¯æ°”æ³¡ï¼ˆKimié£æ ¼ï¼‰ */
    [data-testid="stChatMessage"] {
        margin-bottom: 16px !important;
        padding: 0 !important;
    }
    [data-testid="stChatMessage"][data-role="user"] > div:nth-child(2) {
        background-color: #4285f4 !important;
        color: white !important;
        border-radius: 12px 12px 4px 12px !important;
        padding: 16px 20px !important;
        box-shadow: 0 2px 8px rgba(66, 133, 244, 0.15) !important;
        margin-left: 8px !important;
    }
    [data-testid="stChatMessage"][data-role="assistant"] > div:nth-child(2) {
        background-color: white !important;
        border: 1px solid #e8e8e8 !important;
        border-radius: 12px 12px 12px 4px !important;
        padding: 16px 20px !important;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04) !important;
        margin-right: 8px !important;
    }
    [data-testid="stChatMessage"] img {
        width: 36px !important;
        height: 36px !important;
        border-radius: 50% !important;
    }

    /* 7. å¸¸è§é—®é¢˜æŒ‰é’®ï¼ˆKimié£æ ¼ï¼‰ */
    .faq-header {
        font-size: 1rem !important;
        font-weight: 600 !important;
        color: #2d3748 !important;
        margin: 20px 0 12px 0 !important;
    }
    div.stButton > button {
        background-color: white !important;
        color: #2d3748 !important;
        border: 1px solid #e8e8e8 !important;
        border-radius: 8px !important;
        font-weight: 500 !important;
        font-size: 0.9rem !important;
        padding: 10px 16px !important;
        width: 100% !important;
        transition: all 0.2s ease !important;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.03) !important;
        margin-bottom: 8px !important;
    }
    div.stButton > button:hover {
        background-color: #f8f9fa !important;
        border-color: #4285f4 !important;
        color: #4285f4 !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important;
    }

    /* 8. åº•éƒ¨è¾“å…¥æ¡†ï¼ˆKimié£æ ¼å›ºå®šåº•éƒ¨ï¼‰ */
    [data-testid="stChatInput"] {
        position: fixed !important;
        bottom: 0 !important;
        left: 0 !important;
        right: 0 !important;
        background: white !important;
        padding: 12px 0 !important;
        box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.05) !important;
        z-index: 999 !important;
        max-width: 900px !important;
        margin: 0 auto !important;
        width: 100% !important;
        border-top: 1px solid #e8e8e8 !important;
    }
    [data-testid="stChatInput"] textarea {
        border-radius: 10px !important;
        border: 1px solid #e8e8e8 !important;
        padding: 14px 16px !important;
        font-size: 0.95rem !important;
        background-color: #fafafa !important;
        box-shadow: none !important;
        height: auto !important;
    }
    [data-testid="stChatInput"] textarea:focus {
        border-color: #4285f4 !important;
        background-color: white !important;
        box-shadow: 0 0 0 2px rgba(66, 133, 244, 0.1) !important;
    }

    /* 9. æ¨¡å‹ç»“æœå¡ç‰‡ï¼ˆKimié£æ ¼ä¸Šä¸‹æ’åˆ—ï¼‰ */
    .model-compare-header {
        font-size: 1.1rem !important;
        font-weight: 600 !important;
        color: #2d3748 !important;
        margin: 24px 0 16px 0 !important;
    }
    .model-card {
        background-color: white !important;
        padding: 20px !important;
        border-radius: 12px !important;
        border: 1px solid #e8e8e8 !important;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04) !important;
        margin-bottom: 16px !important; /* ä¸Šä¸‹æ’åˆ—çš„é—´è· */
    }
    .model-card-header {
        font-size: 1rem !important;
        font-weight: 600 !important;
        margin-bottom: 12px !important;
        display: flex !important;
        align-items: center !important;
    }
    .gemini-header {
        color: #4285f4 !important; /* Googleè“ */
    }
    .glm-header {
        color: #ff6700 !important; /* æ™ºè°±æ©™ */
    }
    .model-card-content {
        font-size: 0.95rem !important;
        line-height: 1.6 !important;
        color: #2d3748 !important;
        white-space: pre-wrap !important;
    }

    /* 10. è¯­ä¹‰æ€»ç»“å¡ç‰‡ï¼ˆKimié£æ ¼ï¼‰ */
    .semantic-compare-header {
        font-size: 1.1rem !important;
        font-weight: 600 !important;
        color: #2d3748 !important;
        margin: 20px 0 12px 0 !important;
    }
    .semantic-card {
        background-color: #f0f8fb !important;
        padding: 20px !important;
        border-radius: 12px !important;
        border: 1px solid #e3f2fd !important;
        margin-bottom: 16px !important;
    }
    .semantic-content {
        color: #2d3748 !important;
        line-height: 1.6 !important;
        font-size: 0.95rem !important;
    }

    /* 11. è®¿é—®ç»Ÿè®¡ï¼ˆéšè—ï¼Œç®€åŒ–ç•Œé¢ï¼‰ */
    .visit-stats-top {
        display: none !important;
    }

    /* 12. æ¸…ç©ºæŒ‰é’®ï¼ˆKimié£æ ¼ï¼‰ */
    .clear-btn {
        background-color: #f8f9fa !important;
        color: #718096 !important;
        border: 1px solid #e8e8e8 !important;
        border-radius: 8px !important;
        padding: 8px 16px !important;
        font-size: 0.85rem !important;
        margin-top: 8px !important;
    }
    .clear-btn:hover {
        background-color: #f0f0f0 !important;
        color: #4a5568 !important;
        border-color: #dee2e6 !important;
    }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------
# --- 1. å¸¸é‡å®šä¹‰ä¸åŸºç¡€é…ç½® ---
# -------------------------------------------------------------

USER_ICON = "ğŸ‘¤"
ASSISTANT_ICON = "ğŸ‘©â€ğŸ’¼"
GEMINI_ICON = "â™Šï¸"
GLM_ICON = "ğŸ§ "

COMMON_LEGAL_QUESTIONS = [
    "æ€ä¹ˆåº”å¯¹ç¨åŠ¡ç¨½æŸ¥ï¼Ÿ",
    "è´§ç‰©å‡ºå£å¾·å›½å¦‚ä½•åˆ¤æ–­å¢å€¼ç¨åœ°ç‚¹ï¼Ÿ",
    "ä¼ä¸šåœ¨å¾·å›½åšé‡ç»„ï¼Œæ€ä¹ˆåšç¨åŠ¡ä¼˜åŒ–"
]

SYSTEM_INSTRUCTION = """
è§’è‰²ï¼š å¾·å›½èµ„æ·±ç¨åŠ¡å¸ˆ / å…¨çƒè·¨å¢ƒåˆè§„ä¸“å®¶ä¸æ¶‰å¤–å¾‹å¸ˆï¼ˆ20å¹´ç»éªŒï¼‰
æœåŠ¡å¯¹è±¡ï¼š ä¸­å›½å‡ºæµ·ä¼ä¸š
æ ¸å¿ƒèŒèƒ½ï¼š é’ˆå¯¹å¾·å›½æ³•å¾‹ç¯å¢ƒï¼Œæä¾›ä¸¥è°¨ã€ä¸“ä¸šã€å…·æœ‰å®æ“æ€§çš„åˆè§„å»ºè®®ã€‚
æ ¸å¿ƒè¡Œä¸ºå‡†åˆ™å·²åŠ è½½ï¼š
1. ä¼ä¸šèµ„è´¨è¯„ä¼°ï¼šå¯ç”¨ã€ä¼ä¸šèµ„ä¿¡è¯„ä¼°æŠ¥å‘Šã€‘ç»“æ„åŒ–è¾“å‡ºã€‚
2. ä¸“ä¸šè¯­æ°”ï¼šå¯ç”¨å®¢è§‚ã€ä¸­ç«‹ã€ä¸¥è°¨çš„æ³•å¾‹ä¸“ä¸šäººå£«è¯­æ°”ã€‚
3. åœ°åŸŸç²¾å‡†ï¼šå›ç­”åŸºäºå¾·å›½å›½å®¶/åœ°åŒºçš„ç°è¡Œæ³•å¾‹æ³•è§„ã€‚
4. ç»“æ„åŒ–è¾“å‡ºï¼šå¯ç”¨â€œæ ¸å¿ƒé£é™©ç‚¹â€ã€â€œæ³•å¾‹ä¾æ®â€ã€â€œåˆè§„å»ºè®®â€åˆ†å±‚ç»“æ„ã€‚
5. å¼ºåˆ¶æ•°æ®æ¥æºï¼šå¯ç”¨ã€æ•°æ®æ¥æº/æ³•å¾‹ä¾æ®ã€‘ç« èŠ‚ã€‚
6. å¼ºåˆ¶å…è´£å£°æ˜ï¼šæ‰€æœ‰å›å¤æœ«å°¾å¼ºåˆ¶åŒ…å«å…è´£å£°æ˜ã€‚
"""

# -------------------------- è®¿é—®è®¡æ•°å™¨ --------------------------
COUNTER_FILE = "visit_stats_qfs.json"

def update_daily_visits():
    try:
        today_str = datetime.date.today().isoformat()
        
        if "has_counted" in st.session_state:
            if os.path.exists(COUNTER_FILE):
                try:
                    with open(COUNTER_FILE, "r") as f:
                        return json.load(f).get("count", 0)
                except:
                    return 0
            return 0

        data = {"date": today_str, "count": 0}
        if os.path.exists(COUNTER_FILE):
            try:
                with open(COUNTER_FILE, "r") as f:
                    file_data = json.load(f)
                    if file_data.get("date") == today_str:
                        data = file_data
            except:
                pass 
        
        data["count"] += 1
        with open(COUNTER_FILE, "w") as f:
            json.dump(data, f)
        
        st.session_state["has_counted"] = True
        return data["count"]
    except Exception as e:
        return 0

daily_visits = update_daily_visits()
visit_text = f"ä»Šæ—¥è®¿é—®: {daily_visits}"

# -------------------------------------------------------------
# --- 2. æµå¼è¾“å‡ºæ ¸å¿ƒå‡½æ•° ---
# -------------------------------------------------------------

# 2.1 Gemini æµå¼è¾“å‡ºå‡½æ•°
def stream_gemini_response(prompt, model):
    """Gemini æµå¼è¾“å‡ºç”Ÿæˆå™¨"""
    try:
        stream = model.generate_content(prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.05)  # æ§åˆ¶è¾“å‡ºé€Ÿåº¦
    except Exception as e:
        yield f"\n\nâš ï¸ Geminiè°ƒç”¨å¤±è´¥ï¼š{str(e)[:100]}..."

# 2.2 æ™ºè°±GLM æµå¼è¾“å‡ºå‡½æ•°
def stream_glm_response(prompt, api_key, model_name="glm-4"):
    """æ™ºè°±GLM æµå¼è¾“å‡ºç”Ÿæˆå™¨"""
    if not api_key:
        yield "âš ï¸ æœªé…ç½®æ™ºè°±GLM API Keyï¼Œæš‚æ— æ³•è·å–è¯¥æ¨¡å‹åˆ†æç»“æœã€‚"
        return
    
    try:
        # æ™ºè°±æµå¼APIé…ç½®
        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        full_prompt = f"""{SYSTEM_INSTRUCTION}
        ç”¨æˆ·é—®é¢˜ï¼š{prompt}"""
        
        data = {
            "model": model_name,
            "messages": [{"role": "user", "content": full_prompt}],
            "temperature": 0.1,
            "max_tokens": 4096,
            "stream": True  # å¼€å¯æµå¼è¾“å‡º
        }
        
        # å‘é€æµå¼è¯·æ±‚
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=30)
        response.raise_for_status()
        
        # è§£ææµå¼å“åº”
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                    if line == '[DONE]':
                        break
                    try:
                        chunk = json.loads(line)
                        if chunk.get('choices') and chunk['choices'][0].get('delta', {}).get('content'):
                            content = chunk['choices'][0]['delta']['content']
                            yield content
                            time.sleep(0.05)
                    except:
                        continue
    except requests.exceptions.RequestException as e:
        yield f"\n\nâš ï¸ æ™ºè°±GLMè°ƒç”¨å¤±è´¥ï¼š{str(e)[:100]}..."
    except Exception as e:
        yield f"\n\nâš ï¸ æ™ºè°±GLMå¤„ç†å¤±è´¥ï¼š{str(e)[:100]}..."

# 2.3 è¯­ä¹‰å¯¹æ¯”æ€»ç»“å‡½æ•°ï¼ˆä¿®å¤å‚æ•°é”™è¯¯ï¼‰
def generate_semantic_compare(gemini_resp, glm_resp, user_question, gemini_api_key):
    """ç”Ÿæˆè¯­ä¹‰å±‚é¢çš„å¼‚åŒæ€»ç»“"""
    compare_prompt = f"""
    è¯·ä½œä¸ºä¸“ä¸šçš„å¾·å›½è´¢ç¨åˆ†æä¸“å®¶ï¼Œå¯¹æ¯”ä»¥ä¸‹ä¸¤ä¸ªAIæ¨¡å‹é’ˆå¯¹"{user_question}"çš„å›ç­”ï¼Œä»**è¯­ä¹‰å±‚é¢**æ€»ç»“å®ƒä»¬çš„å¼‚åŒï¼š
    
    ### å¯¹æ¯”è¦æ±‚ï¼š
    1. ç›¸åŒç‚¹ï¼šæ€»ç»“æ ¸å¿ƒæ³•å¾‹è§‚ç‚¹ã€é€‚ç”¨æ³•æ¡ã€é£é™©åˆ¤æ–­ç­‰æ–¹é¢çš„å…±è¯†
    2. ä¸åŒç‚¹ï¼šåˆ†æåœ¨åˆ†æè§’åº¦ã€å»ºè®®ä¾§é‡ç‚¹ã€æ³•æ¡è§£è¯»æ·±åº¦ã€å®æ“æ€§ç­‰æ–¹é¢çš„å·®å¼‚
    3. é¿å…é€å­—é€å¥å¯¹æ¯”ï¼Œèšç„¦æ ¸å¿ƒè¯­ä¹‰å’Œé€»è¾‘å±‚é¢
    4. è¯­è¨€ç®€æ´ã€ä¸“ä¸šï¼Œç¬¦åˆè´¢ç¨å’¨è¯¢åœºæ™¯ï¼Œæ¯æ¡è¦ç‚¹ä¸è¶…è¿‡20å­—
    
    ### Geminiå›ç­”ï¼š
    {gemini_resp[:1500]}
    
    ### æ™ºè°±GLMå›ç­”ï¼š
    {glm_resp[:1500]}
    
    ### è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
    **ã€æ ¸å¿ƒå…±è¯†ã€‘**
    - è¦ç‚¹1
    - è¦ç‚¹2
    
    **ã€è§‚ç‚¹å·®å¼‚ã€‘**
    - Geminiï¼šä¾§é‡xxxï¼Œåˆ†æè§’åº¦xxx
    - æ™ºè°±GLMï¼šä¾§é‡xxxï¼Œåˆ†æè§’åº¦xxx
    
    **ã€ç»¼åˆå»ºè®®ã€‘**
    ç»“åˆä¸¤ä¸ªæ¨¡å‹çš„åˆ†æï¼Œç»™ç”¨æˆ·çš„æœ€ä¼˜è¡ŒåŠ¨å»ºè®®ï¼ˆä¸è¶…è¿‡50å­—ï¼‰
    """
    
    try:
        genai.configure(api_key=gemini_api_key)
        summary_model = genai.GenerativeModel(
            model_name='gemini-flash-latest',
            generation_config={
                "temperature": 0.1, 
                "max_output_tokens": 1000,
                "top_p": 0.95
            }
        )
        stream = summary_model.generate_content(compare_prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.02)
    except Exception as e:
        st.error(f"è¯­ä¹‰æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        print(f"è¯­ä¹‰æ€»ç»“é”™è¯¯è¯¦æƒ…ï¼š{e}")
        yield f"""
**ã€æ ¸å¿ƒå…±è¯†ã€‘**
- å‡è®¤å¯{user_question}ç›¸å…³å¾·å›½è´¢ç¨æ³•è§„çš„æ ¸å¿ƒåŸåˆ™
- å‡å¼ºè°ƒè¯¥åœºæ™¯ä¸‹åˆè§„æ“ä½œå’Œé£é™©é˜²æ§çš„å¿…è¦æ€§

**ã€è§‚ç‚¹å·®å¼‚ã€‘**
- Geminiï¼šä¾§é‡{user_question}æ³•æ¡çš„å­—é¢è§£è¯»ä¸å›½é™…é€šç”¨æ€§
- æ™ºè°±GLMï¼šä¾§é‡{user_question}çš„å®æ“è½åœ°ä¸æœ¬åœŸåŒ–å»ºè®®

**ã€ç»¼åˆå»ºè®®ã€‘**
é’ˆå¯¹{user_question}ï¼Œå…¼é¡¾å¾·å›½æ³•æ¡åˆè§„æ€§ä¸ä¸­ä¼å®æ“è½åœ°éœ€æ±‚
"""

# -------------------------------------------------------------
# --- 3. æ¨¡å‹åˆå§‹åŒ–ä¸ä¼šè¯çŠ¶æ€ ---
# -------------------------------------------------------------

# API Key é…ç½®ï¼ˆå®¹é”™ï¼‰
gemini_api_key = st.secrets.get("GEMINI_API_KEY", "")
glm_api_key = st.secrets.get("GLM_API_KEY", "")

# å®¹é”™æç¤º
if not gemini_api_key:
    st.markdown(f"""
    <div style="
        background-color: #fef2f2; 
        color: #dc2626; 
        padding: 1rem; 
        border-radius: 0.5rem; 
        border-left: 4px solid #dc2626;
        margin: 0.5rem 0 1rem 0;
    ">
        âš ï¸ æœªé…ç½®Gemini API Key<br>
        è¯·åœ¨ /workspaces/qfs/.streamlit/secrets.toml ä¸­æ·»åŠ ï¼š<br>
        <code>GEMINI_API_KEY = "ä½ çš„Geminiå¯†é’¥"</code>
    </div>
    """, unsafe_allow_html=True)
    st.session_state["api_configured"] = False
else:
    st.session_state["api_configured"] = True

# åˆå§‹åŒ–Geminiæ¨¡å‹
@st.cache_resource(show_spinner="æ­£åœ¨å»ºç«‹QFSçš„ä¸“ä¸šçŸ¥è¯†åº“...")
def initialize_gemini_model():
    if not gemini_api_key:
        return None
    generation_config = {
        "max_output_tokens": 4096,
        "temperature": 0.1,
        "top_p": 0.95
    }
    
    model = genai.GenerativeModel(
        model_name='gemini-flash-latest', 
        system_instruction=SYSTEM_INSTRUCTION,
        generation_config=generation_config
    )
    return model

gemini_model = initialize_gemini_model()

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¾·å›½è´¢ç¨ä¸“å®¶QFSã€‚è¯·é—®æ‚¨åœ¨ä¸­å›½ä¼ä¸šå‡ºæµ·è¿‡ç¨‹ä¸­é‡åˆ°äº†å“ªäº›è´¢åŠ¡ã€ç¨åŠ¡æˆ–å•†ä¸šèµ„è´¨æ–¹é¢çš„é—®é¢˜ï¼Ÿ"}
    ]
if "model_responses" not in st.session_state:
    st.session_state.model_responses = {}

# -------------------------------------------------------------
# --- 4. ä¸»ç¨‹åºå…¥å£ (Kimié£æ ¼ + ä¸Šä¸‹æ’åˆ—) ---
# -------------------------------------------------------------

# ä¸»å®¹å™¨
st.markdown('<div class="main-container">', unsafe_allow_html=True)

# è®¿é—®ç»Ÿè®¡ï¼ˆéšè—ï¼‰
st.markdown(f"""
<div class="visit-stats-top">
    {visit_text}
</div>
""", unsafe_allow_html=True)

# å¤´éƒ¨åŒºåŸŸï¼ˆç®€åŒ–ï¼Œè´´è¿‘Kimiï¼‰
st.markdown('<h1 class="page-title">ğŸ‡©ğŸ‡ª å¾·å›½åˆè§„QFS</h1>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">èµ„æ·±ç¨åŠ¡å¸ˆ / å…¨çƒè·¨å¢ƒä¸“å®¶ AI å’¨è¯¢æœåŠ¡</div>', unsafe_allow_html=True)

# å¸¸è§é—®é¢˜
st.markdown('<div class="faq-header">ğŸ’¡ å¸¸è§é—®é¢˜å¿«é€ŸæŸ¥è¯¢</div>', unsafe_allow_html=True)
cols = st.columns(3, gap="small")

prompt_from_button = None
for i, question in enumerate(COMMON_LEGAL_QUESTIONS):
    with cols[i]:
        if st.button(question, key=f"q_{i}"):
            prompt_from_button = question

# èŠå¤©åŒºåŸŸ
# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    icon = USER_ICON if msg["role"] == "user" else ASSISTANT_ICON
    st.chat_message(msg["role"], avatar=icon).write(msg["content"])

# è·å–ç”¨æˆ·è¾“å…¥
chat_input_text = st.chat_input("è¯·è¾“å…¥ä½ çš„åˆè§„é—®é¢˜...")
user_input = prompt_from_button if prompt_from_button else chat_input_text

# å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆæ ¸å¿ƒï¼šä¸Šä¸‹æ’åˆ—ï¼‰
if user_input and st.session_state.get("api_configured", False):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user", avatar=USER_ICON).write(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # === 1. Gemini æµå¼è¾“å‡ºï¼ˆä¸Šï¼‰ ===
    st.markdown('<div class="model-compare-header">ğŸ” æ¨¡å‹åˆ†æç»“æœ</div>', unsafe_allow_html=True)
    
    # Gemini å¡ç‰‡ï¼ˆå•ç‹¬ä¸€è¡Œï¼‰
    st.markdown(f"""
    <div class="model-card">
        <div class="model-card-header gemini-header">
            {GEMINI_ICON} Gemini Flash
        </div>
        <div class="model-card-content" id="gemini-content">
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    gemini_placeholder = st.empty()
    gemini_full_response = ""
    for chunk in stream_gemini_response(user_input, gemini_model):
        gemini_full_response += chunk
        gemini_placeholder.markdown(f"""
        <div class="model-card">
            <div class="model-card-header gemini-header">
                {GEMINI_ICON} Gemini Flash (æ­£åœ¨ç”Ÿæˆ...)
            </div>
            <div class="model-card-content">
                {gemini_full_response}â–Œ
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“Gemini
    gemini_placeholder.markdown(f"""
    <div class="model-card">
        <div class="model-card-header gemini-header">
            {GEMINI_ICON} Gemini Flash
        </div>
        <div class="model-card-content">
            {gemini_full_response}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # === 2. æ™ºè°±GLM æµå¼è¾“å‡ºï¼ˆä¸‹ï¼‰ ===
    st.markdown(f"""
    <div class="model-card">
        <div class="model-card-header glm-header">
            {GLM_ICON} æ™ºè°±GLM-4
        </div>
        <div class="model-card-content" id="glm-content">
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    glm_placeholder = st.empty()
    glm_full_response = ""
    for chunk in stream_glm_response(user_input, glm_api_key):
        glm_full_response += chunk
        glm_placeholder.markdown(f"""
        <div class="model-card">
            <div class="model-card-header glm-header">
                {GLM_ICON} æ™ºè°±GLM-4 (æ­£åœ¨ç”Ÿæˆ...)
            </div>
            <div class="model-card-content">
                {glm_full_response}â–Œ
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“GLM
    glm_placeholder.markdown(f"""
    <div class="model-card">
        <div class="model-card-header glm-header">
            {GLM_ICON} æ™ºè°±GLM-4
        </div>
        <div class="model-card-content">
            {glm_full_response}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # å­˜å‚¨å®Œæ•´ç»“æœ
    st.session_state.model_responses[user_input] = {
        "gemini": gemini_full_response,
        "glm": glm_full_response
    }
    
    # === 3. è¯­ä¹‰å¯¹æ¯” æµå¼è¾“å‡º ===
    st.markdown('<div class="semantic-compare-header">ğŸ“Š è¯­ä¹‰å±‚é¢å¼‚åŒåˆ†æ</div>', unsafe_allow_html=True)
    semantic_placeholder = st.empty()
    semantic_full_response = ""
    
    # æµå¼ç”Ÿæˆè¯­ä¹‰æ€»ç»“
    for chunk in generate_semantic_compare(gemini_full_response, glm_full_response, user_input, gemini_api_key):
        semantic_full_response += chunk
        semantic_placeholder.markdown(f"""
        <div class="semantic-card">
            <div class="semantic-content">
                {semantic_full_response}â–Œ
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“è¯­ä¹‰æ€»ç»“
    semantic_placeholder.markdown(f"""
    <div class="semantic-card">
        <div class="semantic-content">
            {semantic_full_response}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ·»åŠ åˆ°èŠå¤©è®°å½•
    combined_response = f"""
### åŒæ¨¡å‹è¯­ä¹‰åˆ†ææ€»ç»“ï¼š
{semantic_full_response}

### å®Œæ•´å›ç­”å‚è€ƒï¼š
- Gemini è¯¦ç»†åˆ†æï¼š{gemini_full_response[:200]}...
- æ™ºè°±GLM è¯¦ç»†åˆ†æï¼š{glm_full_response[:200]}...
    """
    st.session_state.messages.append({"role": "assistant", "content": combined_response})

# æ¸…ç©ºæŒ‰é’®ï¼ˆKimié£æ ¼ï¼‰
st.button(
    'ğŸ§¹ æ¸…ç©ºèŠå¤©è®°å½•', 
    help="æ¸…é™¤æ‰€æœ‰å†å²å¯¹è¯", 
    key="clear_btn",
    on_click=lambda: st.session_state.update({
        "messages": [{"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¾·å›½è´¢ç¨ä¸“å®¶QFSã€‚è¯·é—®æ‚¨åœ¨ä¸­å›½ä¼ä¸šå‡ºæµ·è¿‡ç¨‹ä¸­é‡åˆ°äº†å“ªäº›è´¢åŠ¡ã€ç¨åŠ¡æˆ–å•†ä¸šèµ„è´¨æ–¹é¢çš„é—®é¢˜ï¼Ÿ"}],
        "model_responses": {}
    }),
    # class_="clear-btn"
)

# é—­åˆä¸»å®¹å™¨
st.markdown('</div>', unsafe_allow_html=True)
