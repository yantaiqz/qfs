import streamlit as st
import google.generativeai as genai
import requests
import json
import datetime
import os
import time
import re  # æ–°å¢ï¼šç”¨äºæ¸…ç†å†—ä½™æ¢è¡Œ

# -------------------------------------------------------------
# --- 0. é¡µé¢é…ç½®å’Œ CSS æ³¨å…¥ (Kimié£æ ¼ + æ— é¡¶éƒ¨ç©ºç™½ + ä¸Šä¸‹æ’åˆ—) ---
# -------------------------------------------------------------

st.set_page_config(
    page_title="å¾·å›½è´¢ç¨ä¸“å®¶QFS", 
    page_icon="ğŸ‡©ğŸ‡ª", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Kimié£æ ¼ CSS æ³¨å…¥ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šè§£å†³ç©ºç™½è¡Œã€ä¼˜åŒ–æ’ç‰ˆï¼‰
st.markdown("""
<style>
    /* 1. å½»åº•ç§»é™¤æ‰€æœ‰é»˜è®¤ç©ºç™½å’Œè¾¹è· */
    html, body, [data-testid="stAppViewContainer"], [data-testid="stMain"] {
        padding: 0 !important;
        margin: 0 !important;
        background-color: #f5f7fa !important;
    }
    
    /* 2. éšè—æ‰€æœ‰é»˜è®¤å…ƒç´  */
    header, [data-testid="stSidebar"], footer, .stDeployButton, [data-testid="stToolbar"],
    [data-testid="stDecoration"], [data-testid="stStatusWidget"] {
        display: none !important;
    }
    
    /* 3. å…¨å±€æ ·å¼ï¼ˆKimié£æ ¼ï¼‰ */
    .stApp {
        background-color: #f5f7fa !important;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
        padding: 0 !important;
        margin: 0 !important;
        max-width: 100% !important;
    }

    /* 4. ä¸»å®¹å™¨ï¼ˆKimié£æ ¼å±…ä¸­+çª„è¾¹è·ï¼‰ */
    .main-container {
        max-width: 900px !important;
        width: 100% !important;
        margin: 0 auto !important;
        padding: 16px 24px 80px 24px !important; /* åº•éƒ¨ç•™ç©ºç»™è¾“å…¥æ¡† */
        box-sizing: border-box !important;
    }

    /* 5. æ ‡é¢˜åŒºåŸŸï¼ˆKimié£æ ¼ï¼‰ */
    .page-title {
        font-size: 2rem !important;
        font-weight: 600 !important;
        color: #2d3748 !important;
        margin: 8px 0 12px 0 !important;
        line-height: 1.3 !important;
    }
    .subtitle {
        font-size: 0.95rem !important;
        color: #718096 !important;
        margin: 0 0 24px 0 !important;
        font-weight: 400 !important;
        line-height: 1.5 !important;
    }

    /* 6. èŠå¤©æ¶ˆæ¯æ°”æ³¡ï¼ˆKimié£æ ¼ï¼‰ */
    [data-testid="stChatMessage"] {
        margin-bottom: 16px !important;
        padding: 0 !important;
    }
    [data-testid="stChatMessage"][data-role="user"] > div:nth-child(2) {
        background-color: #4285f4 !important;
        color: white !important;
        border-radius: 12px 12px 4px 12px !important;
        padding: 16px 20px !important;
        box-shadow: 0 2px 8px rgba(66, 133, 244, 0.15) !important;
        margin-left: 8px !important;
    }
    [data-testid="stChatMessage"][data-role="assistant"] > div:nth-child(2) {
        background-color: white !important;
        border: 1px solid #e8e8e8 !important;
        border-radius: 12px 12px 12px 4px !important;
        padding: 16px 20px !important;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04) !important;
        margin-right: 8px !important;
    }
    [data-testid="stChatMessage"] img {
        width: 36px !important;
        height: 36px !important;
        border-radius: 50% !important;
    }

    /* 7. å¸¸è§é—®é¢˜æŒ‰é’®ï¼ˆKimié£æ ¼ï¼‰ */
    .faq-header {
        font-size: 1rem !important;
        font-weight: 600 !important;
        color: #2d3748 !important;
        margin: 20px 0 12px 0 !important;
    }
    div.stButton > button {
        background-color: white !important;
        color: #2d3748 !important;
        border: 1px solid #e8e8e8 !important;
        border-radius: 8px !important;
        font-weight: 500 !important;
        font-size: 0.9rem !important;
        padding: 10px 16px !important;
        width: 100% !important;
        transition: all 0.2s ease !important;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.03) !important;
        margin-bottom: 8px !important;
    }
    div.stButton > button:hover {
        background-color: #f8f9fa !important;
        border-color: #4285f4 !important;
        color: #4285f4 !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05) !important;
    }

    /* 8. åº•éƒ¨è¾“å…¥æ¡†ï¼ˆKimié£æ ¼å›ºå®šåº•éƒ¨ï¼‰ */
    [data-testid="stChatInput"] {
        position: fixed !important;
        bottom: 0 !important;
        left: 0 !important;
        right: 0 !important;
        background: white !important;
        padding: 12px 0 !important;
        box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.05) !important;
        z-index: 999 !important;
        max-width: 900px !important;
        margin: 0 auto !important;
        width: 100% !important;
        border-top: 1px solid #e8e8e8 !important;
    }
    [data-testid="stChatInput"] textarea {
        border-radius: 10px !important;
        border: 1px solid #e8e8e8 !important;
        padding: 14px 16px !important;
        font-size: 0.95rem !important;
        background-color: #fafafa !important;
        box-shadow: none !important;
        height: auto !important;
    }
    [data-testid="stChatInput"] textarea:focus {
        border-color: #4285f4 !important;
        background-color: white !important;
        box-shadow: 0 0 0 2px rgba(66, 133, 244, 0.1) !important;
    }

    /* 9. æ¨¡å‹ç»“æœå¡ç‰‡ï¼ˆKimié£æ ¼ä¸Šä¸‹æ’åˆ—ï¼‰ */
    .model-compare-header {
        font-size: 1.1rem !important;
        font-weight: 600 !important;
        color: #2d3748 !important;
        margin: 24px 0 16px 0 !important;
    }
    .model-card {
        background-color: white !important;
        padding: 16px 20px !important; /* å‡å°‘å†…è¾¹è·ï¼Œé¿å…ç©ºç™½ */
        border-radius: 12px !important;
        border: 1px solid #e8e8e8 !important;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04) !important;
        margin-bottom: 16px !important; /* ä¸Šä¸‹æ’åˆ—çš„é—´è· */
    }
    .model-card-header {
        font-size: 1rem !important;
        font-weight: 600 !important;
        margin-bottom: 12px !important;
        display: flex !important;
        align-items: center !important;
    }
    .gemini-header {
        color: #4285f4 !important; /* Googleè“ */
    }
    .glm-header {
        color: #ff6700 !important; /* æ™ºè°±æ©™ */
    }
    .model-card-content {
        font-size: 0.95rem !important;
        line-height: 1.5 !important; /* ä¼˜åŒ–è¡Œé«˜ï¼Œå‡å°‘ç©ºç™½ */
        color: #2d3748 !important;
        white-space: pre-wrap !important;
    }

    /* 10. è¯­ä¹‰æ€»ç»“å¡ç‰‡ï¼ˆKimié£æ ¼ + è§£å†³ç©ºç™½è¡Œï¼‰ */
    .semantic-compare-header {
        font-size: 1.1rem !important;
        font-weight: 600 !important;
        color: #2d3748 !important;
        margin: 20px 0 12px 0 !important;
    }
    .semantic-card {
        background-color: #f0f8fb !important;
        padding: 16px 20px !important; /* å‡å°‘å†…è¾¹è· */
        border-radius: 12px !important;
        border: 1px solid #e3f2fd !important;
        margin-bottom: 16px !important;
    }
    .semantic-content {
        color: #2d3748 !important;
        line-height: 1.5 !important; /* ä¼˜åŒ–è¡Œé«˜ */
        font-size: 0.95rem !important;
    }
    /* å…³é”®ï¼šæ§åˆ¶æ¢è¡Œé—´è·ï¼Œè§£å†³ç©ºç™½è¡Œ */
    .semantic-content br, .model-card-content br {
        line-height: 1.2 !important;
        margin: 2px 0 !important;
    }
    p {
        margin: 4px 0 !important;
        padding: 0 !important;
    }

    /* 11. è®¿é—®ç»Ÿè®¡ï¼ˆéšè—ï¼Œç®€åŒ–ç•Œé¢ï¼‰ */
    .visit-stats-top {
        display: none !important;
    }

    /* 12. æ¸…ç©ºæŒ‰é’®ï¼ˆKimié£æ ¼ï¼‰ */
    .clear-btn {
        background-color: #f8f9fa !important;
        color: #718096 !important;
        border: 1px solid #e8e8e8 !important;
        border-radius: 8px !important;
        padding: 8px 16px !important;
        font-size: 0.85rem !important;
        margin-top: 8px !important;
    }
    .clear-btn:hover {
        background-color: #f0f0f0 !important;
        color: #4a5568 !important;
        border-color: #dee2e6 !important;
    }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------
# --- å·¥å…·å‡½æ•°ï¼šæ¸…ç†å†—ä½™æ¢è¡Œ/ç©ºæ ¼ ---
# -------------------------------------------------------------
def clean_extra_newlines(text):
    """åˆå¹¶è¿ç»­æ¢è¡Œç¬¦ä¸ºå•ä¸ªï¼Œæ¸…ç†å†—ä½™ç©ºæ ¼/åˆ¶è¡¨ç¬¦ï¼Œä¿ç•™ç»“æ„"""
    # åˆå¹¶2ä¸ªåŠä»¥ä¸Šæ¢è¡Œç¬¦ä¸º1ä¸ª
    cleaned = re.sub(r'\n{2,}', '\n', text)
    # ç§»é™¤å…¨è§’ç©ºæ ¼
    cleaned = re.sub(r'ã€€+', '', cleaned)
    # ç§»é™¤åˆ¶è¡¨ç¬¦
    cleaned = re.sub(r'\t+', '', cleaned)
    # ç§»é™¤å¼€å¤´/ç»“å°¾çš„ç©ºæ¢è¡Œ
    cleaned = cleaned.strip('\n')
    # ç¡®ä¿åˆ—è¡¨å‰åªæœ‰ä¸€ä¸ªæ¢è¡Œ
    cleaned = re.sub(r'\n+(- )', '\n- ', cleaned)
    return cleaned

# -------------------------------------------------------------
# --- 1. å¸¸é‡å®šä¹‰ä¸åŸºç¡€é…ç½® ---
# -------------------------------------------------------------

USER_ICON = "ğŸ‘¤"
ASSISTANT_ICON = "ğŸ‘©â€ğŸ’¼"
GEMINI_ICON = "â™Šï¸"
GLM_ICON = "ğŸ§ "

COMMON_LEGAL_QUESTIONS = [
    "æ€ä¹ˆåº”å¯¹ç¨åŠ¡ç¨½æŸ¥ï¼Ÿ",
    "è´§ç‰©å‡ºå£å¾·å›½å¦‚ä½•åˆ¤æ–­å¢å€¼ç¨åœ°ç‚¹ï¼Ÿ",
    "ä¼ä¸šåœ¨å¾·å›½åšé‡ç»„ï¼Œæ€ä¹ˆåšç¨åŠ¡ä¼˜åŒ–"
]

# ä¼˜åŒ–åçš„ç³»ç»ŸæŒ‡ä»¤ï¼šè¦æ±‚è¯¦ç»†è¾“å‡º+å‡å°‘å†—ä½™æ¢è¡Œ
SYSTEM_INSTRUCTION = """
è§’è‰²ï¼š å¾·å›½èµ„æ·±ç¨åŠ¡å¸ˆ / å…¨çƒè·¨å¢ƒåˆè§„ä¸“å®¶ä¸æ¶‰å¤–å¾‹å¸ˆï¼ˆ20å¹´ç»éªŒï¼‰
æœåŠ¡å¯¹è±¡ï¼š ä¸­å›½å‡ºæµ·ä¼ä¸š
æ ¸å¿ƒèŒèƒ½ï¼š é’ˆå¯¹å¾·å›½æ³•å¾‹ç¯å¢ƒï¼Œæä¾›ä¸¥è°¨ã€ä¸“ä¸šã€å…·æœ‰å®æ“æ€§çš„åˆè§„å»ºè®®ã€‚
æ ¸å¿ƒè¡Œä¸ºå‡†åˆ™å·²åŠ è½½ï¼š
1. ä¼ä¸šèµ„è´¨è¯„ä¼°ï¼šå¯ç”¨ã€ä¼ä¸šèµ„ä¿¡è¯„ä¼°æŠ¥å‘Šã€‘ç»“æ„åŒ–è¾“å‡ºã€‚
2. ä¸“ä¸šè¯­æ°”ï¼šå¯ç”¨å®¢è§‚ã€ä¸­ç«‹ã€ä¸¥è°¨çš„æ³•å¾‹ä¸“ä¸šäººå£«è¯­æ°”ã€‚
3. åœ°åŸŸç²¾å‡†ï¼šå›ç­”åŸºäºå¾·å›½å›½å®¶/åœ°åŒºçš„ç°è¡Œæ³•å¾‹æ³•è§„ã€‚
4. ç»“æ„åŒ–è¾“å‡ºï¼šå¯ç”¨â€œæ ¸å¿ƒé£é™©ç‚¹â€ã€â€œæ³•å¾‹ä¾æ®â€ã€â€œåˆè§„å»ºè®®â€åˆ†å±‚ç»“æ„ï¼Œå†…å®¹è¯¦ç»†ä¸”å®Œæ•´ã€‚
5. å¼ºåˆ¶æ•°æ®æ¥æºï¼šå¯ç”¨ã€æ•°æ®æ¥æº/æ³•å¾‹ä¾æ®ã€‘ç« èŠ‚ã€‚
6. å¼ºåˆ¶å…è´£å£°æ˜ï¼šå›å¤æœ«å°¾åŒ…å«ç®€æ˜å…è´£å£°æ˜ï¼ˆä¸è¶…è¿‡50å­—ï¼‰ã€‚
7. æ’ç‰ˆè¦æ±‚ï¼šä½¿ç”¨å•ä¸ªæ¢è¡Œåˆ†éš”æ®µè½/åˆ†ç‚¹ï¼Œç¦æ­¢ä½¿ç”¨å¤šä¸ªè¿ç»­æ¢è¡Œã€å…¨è§’ç©ºæ ¼æˆ–åˆ¶è¡¨ç¬¦ã€‚
"""

# -------------------------- è®¿é—®è®¡æ•°å™¨ --------------------------
COUNTER_FILE = "visit_stats_qfs.json"

def update_daily_visits():
    try:
        today_str = datetime.date.today().isoformat()
        
        if "has_counted" in st.session_state:
            if os.path.exists(COUNTER_FILE):
                try:
                    with open(COUNTER_FILE, "r") as f:
                        return json.load(f).get("count", 0)
                except:
                    return 0
            return 0

        data = {"date": today_str, "count": 0}
        if os.path.exists(COUNTER_FILE):
            try:
                with open(COUNTER_FILE, "r") as f:
                    file_data = json.load(f)
                    if file_data.get("date") == today_str:
                        data = file_data
            except:
                pass 
        
        data["count"] += 1
        with open(COUNTER_FILE, "w") as f:
            json.dump(data, f)
        
        st.session_state["has_counted"] = True
        return data["count"]
    except Exception as e:
        return 0

daily_visits = update_daily_visits()
visit_text = f"ä»Šæ—¥è®¿é—®: {daily_visits}"

# -------------------------------------------------------------
# --- 2. æµå¼è¾“å‡ºæ ¸å¿ƒå‡½æ•° ---
# -------------------------------------------------------------

# 2.1 Gemini æµå¼è¾“å‡ºå‡½æ•°
def stream_gemini_response(prompt, model):
    """Gemini æµå¼è¾“å‡ºç”Ÿæˆå™¨ï¼ˆä¼˜åŒ–ï¼šå‡å°‘æ¢è¡Œï¼‰"""
    try:
        stream = model.generate_content(prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.05)  # æ§åˆ¶è¾“å‡ºé€Ÿåº¦
    except Exception as e:
        yield f"\n\nâš ï¸ Geminiè°ƒç”¨å¤±è´¥ï¼š{str(e)[:100]}..."

# 2.2 æ™ºè°±GLM æµå¼è¾“å‡ºå‡½æ•°
def stream_glm_response(prompt, api_key, model_name="glm-4"):
    """æ™ºè°±GLM æµå¼è¾“å‡ºç”Ÿæˆå™¨ï¼ˆä¼˜åŒ–ï¼šå‡å°‘æ¢è¡Œï¼‰"""
    if not api_key:
        yield "âš ï¸ æœªé…ç½®æ™ºè°±GLM API Keyï¼Œæš‚æ— æ³•è·å–è¯¥æ¨¡å‹åˆ†æç»“æœã€‚"
        return
    
    try:
        # æ™ºè°±æµå¼APIé…ç½®
        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        # ä¼˜åŒ–promptï¼šè¦æ±‚è¯¦ç»†è¾“å‡º+å‡å°‘å†—ä½™æ¢è¡Œ
        full_prompt = f"""{SYSTEM_INSTRUCTION}
        ç”¨æˆ·é—®é¢˜ï¼š{prompt}
        é¢å¤–è¦æ±‚ï¼šå›ç­”å†…å®¹è¯¦ç»†å®Œæ•´ï¼Œä½¿ç”¨å•ä¸ªæ¢è¡Œåˆ†éš”åˆ†ç‚¹/æ®µè½ï¼Œç¦æ­¢å¤šä¸ªè¿ç»­æ¢è¡Œï¼Œæ€»é•¿åº¦ä¸å°‘äº500å­—ã€‚"""
        
        data = {
            "model": model_name,
            "messages": [{"role": "user", "content": full_prompt}],
            "temperature": 0.1,
            "max_tokens": 4096,
            "stream": True  # å¼€å¯æµå¼è¾“å‡º
        }
        
        # å‘é€æµå¼è¯·æ±‚
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=30)
        response.raise_for_status()
        
        # è§£ææµå¼å“åº”
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                    if line == '[DONE]':
                        break
                    try:
                        chunk = json.loads(line)
                        if chunk.get('choices') and chunk['choices'][0].get('delta', {}).get('content'):
                            content = chunk['choices'][0]['delta']['content']
                            yield content
                            time.sleep(0.05)
                    except:
                        continue
    except requests.exceptions.RequestException as e:
        yield f"\n\nâš ï¸ æ™ºè°±GLMè°ƒç”¨å¤±è´¥ï¼š{str(e)[:100]}..."
    except Exception as e:
        yield f"\n\nâš ï¸ æ™ºè°±GLMå¤„ç†å¤±è´¥ï¼š{str(e)[:100]}..."

# 2.3 è¯­ä¹‰å¯¹æ¯”æ€»ç»“å‡½æ•°ï¼ˆè§£å†³æˆªæ–­+ç©ºç™½è¡Œï¼‰
def generate_semantic_compare(gemini_resp, glm_resp, user_question, gemini_api_key):
    """ç”Ÿæˆè¯­ä¹‰å±‚é¢çš„å¼‚åŒæ€»ç»“ï¼ˆæå‡tokenä¸Šé™+æ”¾å®½çº¦æŸï¼‰"""
    compare_prompt = f"""
    è¯·ä½œä¸ºä¸“ä¸šçš„å¾·å›½è´¢ç¨åˆ†æä¸“å®¶ï¼Œå¯¹æ¯”ä»¥ä¸‹ä¸¤ä¸ªAIæ¨¡å‹é’ˆå¯¹"{user_question}"çš„å›ç­”ï¼Œä»**è¯­ä¹‰å±‚é¢**æ€»ç»“å®ƒä»¬çš„å¼‚åŒï¼š
    
    ### å¯¹æ¯”è¦æ±‚ï¼š
    1. ç›¸åŒç‚¹ï¼šæ€»ç»“æ ¸å¿ƒæ³•å¾‹è§‚ç‚¹ã€é€‚ç”¨æ³•æ¡ã€é£é™©åˆ¤æ–­ç­‰æ–¹é¢çš„å…±è¯†ï¼ˆ3-5æ¡ï¼‰
    2. ä¸åŒç‚¹ï¼šè¯¦ç»†åˆ†æä¸¤ä¸ªæ¨¡å‹åœ¨åˆ†æè§’åº¦ã€å»ºè®®ä¾§é‡ç‚¹ã€æ³•æ¡è§£è¯»æ·±åº¦ã€å®æ“æ€§ç­‰æ–¹é¢çš„å·®å¼‚
    3. é¿å…é€å­—é€å¥å¯¹æ¯”ï¼Œèšç„¦æ ¸å¿ƒè¯­ä¹‰å’Œé€»è¾‘å±‚é¢
    4. è¯­è¨€ç®€æ´ã€ä¸“ä¸šï¼Œç¬¦åˆè´¢ç¨å’¨è¯¢åœºæ™¯ï¼Œç¦æ­¢ä½¿ç”¨å¤šä¸ªè¿ç»­æ¢è¡Œ
    
    ### Geminiå›ç­”ï¼š
    {gemini_resp[:2000]}  # æå‡æˆªæ–­é•¿åº¦ï¼Œç¡®ä¿ç´ æå……è¶³
    
    ### æ™ºè°±GLMå›ç­”ï¼š
    {glm_resp[:2000]}
    
    ### è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼Œå†…å®¹å®Œæ•´ï¼‰ï¼š
    **ã€æ ¸å¿ƒå…±è¯†ã€‘**
    - è¦ç‚¹1
    - è¦ç‚¹2
    - è¦ç‚¹3
    
    **ã€è§‚ç‚¹å·®å¼‚ã€‘**
    - Geminiï¼šä¾§é‡çš„åˆ†æè§’åº¦ã€å»ºè®®ä¾§é‡ç‚¹ã€ä¼˜åŠ¿ä¸ä¸è¶³
    - æ™ºè°±GLMï¼šä¾§é‡çš„åˆ†æè§’åº¦ã€å»ºè®®ä¾§é‡ç‚¹ã€ä¼˜åŠ¿ä¸ä¸è¶³
    
    **ã€ç»¼åˆå»ºè®®ã€‘**
    ç»“åˆä¸¤ä¸ªæ¨¡å‹çš„åˆ†æï¼Œç»™ç”¨æˆ·çš„å…·ä½“ã€å¯è½åœ°çš„æœ€ä¼˜è¡ŒåŠ¨å»ºè®®ï¼ˆä¸å°‘äº50å­—ï¼‰
    """
    
    try:
        genai.configure(api_key=gemini_api_key)
        summary_model = genai.GenerativeModel(
            model_name='gemini-flash-latest',
            generation_config={
                "temperature": 0.1, 
                "max_output_tokens": 3000,  # å¤§å¹…æå‡tokenä¸Šé™ï¼Œé¿å…æˆªæ–­
                "top_p": 0.95
            }
        )
        stream = summary_model.generate_content(compare_prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.02)  # ç¼©çŸ­ç­‰å¾…ï¼Œå‡å°‘è¶…æ—¶
    except Exception as e:
        # ç²¾å‡†æç¤ºé”™è¯¯+å®Œæ•´é™çº§æ¨¡æ¿
        st.error(f"è¯­ä¹‰æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        print(f"è¯­ä¹‰æ€»ç»“é”™è¯¯è¯¦æƒ…ï¼š{e}")
        yield f"""
**ã€æ ¸å¿ƒå…±è¯†ã€‘**
- å‡è®¤å¯{user_question}ç›¸å…³å¾·å›½è´¢ç¨æ³•è§„çš„æ ¸å¿ƒé€‚ç”¨åŸåˆ™
- å‡å¼ºè°ƒè¯¥åœºæ™¯ä¸‹åˆè§„æ“ä½œçš„é‡è¦æ€§å’Œé£é™©é˜²æ§çš„å¿…è¦æ€§
- å‡è®¤ä¸ºä¸“ä¸šçš„ç¨åŠ¡åˆè§„æ–‡ä»¶å‡†å¤‡æ˜¯æ ¸å¿ƒè¦åŠ¡

**ã€è§‚ç‚¹å·®å¼‚ã€‘**
- Geminiï¼šä¾§é‡{user_question}ç›¸å…³æ³•æ¡çš„å­—é¢è§£è¯»ã€å›½é™…é€šç”¨æ€§å’Œåˆè§„æ¡†æ¶æ­å»º
- æ™ºè°±GLMï¼šä¾§é‡{user_question}åœºæ™¯ä¸‹ä¸­å›½ä¼ä¸šçš„å®æ“è½åœ°ã€æœ¬åœŸåŒ–é€‚é…å’Œæµç¨‹ç®€åŒ–

**ã€ç»¼åˆå»ºè®®ã€‘**
é’ˆå¯¹{user_question}é—®é¢˜ï¼Œå»ºè®®ç»“åˆGeminiçš„åˆè§„æ¡†æ¶å’Œæ™ºè°±GLMçš„å®æ“å»ºè®®ï¼Œå…ˆç¡®ä¿ç¬¦åˆå¾·å›½è´¢ç¨æ³•è§„çš„æ ¸å¿ƒè¦æ±‚ï¼Œå†æ ¹æ®ä¸­ä¼å‡ºæµ·çš„å®é™…åœºæ™¯ä¼˜åŒ–è½åœ°æµç¨‹ï¼Œå¿…è¦æ—¶å’¨è¯¢å½“åœ°ä¸“ä¸šç¨åŠ¡å¸ˆã€‚
"""

# -------------------------------------------------------------
# --- 3. æ¨¡å‹åˆå§‹åŒ–ä¸ä¼šè¯çŠ¶æ€ ---
# -------------------------------------------------------------

# API Key é…ç½®ï¼ˆå®¹é”™ï¼‰
gemini_api_key = st.secrets.get("GEMINI_API_KEY", "")
glm_api_key = st.secrets.get("GLM_API_KEY", "")

# å®¹é”™æç¤º
if not gemini_api_key:
    st.markdown(f"""
    <div style="
        background-color: #fef2f2; 
        color: #dc2626; 
        padding: 1rem; 
        border-radius: 0.5rem; 
        border-left: 4px solid #dc2626;
        margin: 0.5rem 0 1rem 0;
    ">
        âš ï¸ æœªé…ç½®Gemini API Key<br>
        è¯·åœ¨ /workspaces/qfs/.streamlit/secrets.toml ä¸­æ·»åŠ ï¼š<br>
        <code>GEMINI_API_KEY = "ä½ çš„Geminiå¯†é’¥"</code>
    </div>
    """, unsafe_allow_html=True)
    st.session_state["api_configured"] = False
else:
    st.session_state["api_configured"] = True

# åˆå§‹åŒ–Geminiæ¨¡å‹
@st.cache_resource(show_spinner="æ­£åœ¨å»ºç«‹QFSçš„ä¸“ä¸šçŸ¥è¯†åº“...")
def initialize_gemini_model():
    if not gemini_api_key:
        return None
    generation_config = {
        "max_output_tokens": 4096,
        "temperature": 0.1,
        "top_p": 0.95
    }
    
    model = genai.GenerativeModel(
        model_name='gemini-flash-latest', 
        system_instruction=SYSTEM_INSTRUCTION,
        generation_config=generation_config
    )
    return model

gemini_model = initialize_gemini_model()

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¾·å›½è´¢ç¨ä¸“å®¶QFSã€‚è¯·é—®æ‚¨åœ¨ä¸­å›½ä¼ä¸šå‡ºæµ·è¿‡ç¨‹ä¸­é‡åˆ°äº†å“ªäº›è´¢åŠ¡ã€ç¨åŠ¡æˆ–å•†ä¸šèµ„è´¨æ–¹é¢çš„é—®é¢˜ï¼Ÿ"}
    ]
if "model_responses" not in st.session_state:
    st.session_state.model_responses = {}

# -------------------------------------------------------------
# --- 4. ä¸»ç¨‹åºå…¥å£ (Kimié£æ ¼ + ä¸Šä¸‹æ’åˆ— + æ— ç©ºç™½è¡Œ) ---
# -------------------------------------------------------------

# ä¸»å®¹å™¨
st.markdown('<div class="main-container">', unsafe_allow_html=True)

# è®¿é—®ç»Ÿè®¡ï¼ˆéšè—ï¼‰
st.markdown(f"""
<div class="visit-stats-top">
    {visit_text}
</div>
""", unsafe_allow_html=True)

# å¤´éƒ¨åŒºåŸŸï¼ˆç®€åŒ–ï¼Œè´´è¿‘Kimiï¼‰
st.markdown('<h1 class="page-title">ğŸ‡©ğŸ‡ª å¾·å›½åˆè§„QFS</h1>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">èµ„æ·±ç¨åŠ¡å¸ˆ / å…¨çƒè·¨å¢ƒä¸“å®¶ AI å’¨è¯¢æœåŠ¡</div>', unsafe_allow_html=True)

# å¸¸è§é—®é¢˜
st.markdown('<div class="faq-header">ğŸ’¡ å¸¸è§é—®é¢˜å¿«é€ŸæŸ¥è¯¢</div>', unsafe_allow_html=True)
cols = st.columns(3, gap="small")

prompt_from_button = None
for i, question in enumerate(COMMON_LEGAL_QUESTIONS):
    with cols[i]:
        if st.button(question, key=f"q_{i}"):
            prompt_from_button = question

# èŠå¤©åŒºåŸŸ
# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    icon = USER_ICON if msg["role"] == "user" else ASSISTANT_ICON
    st.chat_message(msg["role"], avatar=icon).write(msg["content"])

# è·å–ç”¨æˆ·è¾“å…¥
chat_input_text = st.chat_input("è¯·è¾“å…¥ä½ çš„åˆè§„é—®é¢˜...")
user_input = prompt_from_button if prompt_from_button else chat_input_text

# å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆæ ¸å¿ƒï¼šä¸Šä¸‹æ’åˆ— + è§£å†³ç©ºç™½è¡Œ/æˆªæ–­ï¼‰
if user_input and st.session_state.get("api_configured", False):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user", avatar=USER_ICON).write(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # === 1. Gemini æµå¼è¾“å‡ºï¼ˆä¸Šï¼‰ ===
    st.markdown('<div class="model-compare-header">ğŸ” æ¨¡å‹åˆ†æç»“æœ</div>', unsafe_allow_html=True)
    
    # Gemini å¡ç‰‡ï¼ˆå•ç‹¬ä¸€è¡Œï¼‰
    st.markdown(f"""
    <div class="model-card">
        <div class="model-card-header gemini-header">
            {GEMINI_ICON} Gemini Flash
        </div>
        <div class="model-card-content" id="gemini-content">
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    gemini_placeholder = st.empty()
    gemini_full_response = ""
    for chunk in stream_gemini_response(user_input, gemini_model):
        gemini_full_response += chunk
        # æ¸…ç†å†—ä½™æ¢è¡Œ + æ¸²æŸ“
        cleaned_gemini = clean_extra_newlines(gemini_full_response)
        display_gemini = cleaned_gemini.replace("\n", "<br>")
        gemini_placeholder.markdown(f"""
        <div class="model-card">
            <div class="model-card-header gemini-header">
                {GEMINI_ICON} Gemini Flash (æ­£åœ¨ç”Ÿæˆ...)
            </div>
            <div class="model-card-content">
                {display_gemini}â–Œ
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“Geminiï¼ˆæ¸…ç†ç©ºç™½è¡Œï¼‰
    final_gemini = clean_extra_newlines(gemini_full_response)
    final_display_gemini = final_gemini.replace("\n", "<br>")
    gemini_placeholder.markdown(f"""
    <div class="model-card">
        <div class="model-card-header gemini-header">
            {GEMINI_ICON} Gemini Flash
        </div>
        <div class="model-card-content">
            {final_display_gemini}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # === 2. æ™ºè°±GLM æµå¼è¾“å‡ºï¼ˆä¸‹ï¼‰ ===
    st.markdown(f"""
    <div class="model-card">
        <div class="model-card-header glm-header">
            {GLM_ICON} æ™ºè°±GLM-4
        </div>
        <div class="model-card-content" id="glm-content">
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    glm_placeholder = st.empty()
    glm_full_response = ""
    for chunk in stream_glm_response(user_input, glm_api_key):
        glm_full_response += chunk
        # æ¸…ç†å†—ä½™æ¢è¡Œ + æ¸²æŸ“
        cleaned_glm = clean_extra_newlines(glm_full_response)
        display_glm = cleaned_glm.replace("\n", "<br>")
        glm_placeholder.markdown(f"""
        <div class="model-card">
            <div class="model-card-header glm-header">
                {GLM_ICON} æ™ºè°±GLM-4 (æ­£åœ¨ç”Ÿæˆ...)
            </div>
            <div class="model-card-content">
                {display_glm}â–Œ
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“GLMï¼ˆæ¸…ç†ç©ºç™½è¡Œï¼‰
    final_glm = clean_extra_newlines(glm_full_response)
    final_display_glm = final_glm.replace("\n", "<br>")
    glm_placeholder.markdown(f"""
    <div class="model-card">
        <div class="model-card-header glm-header">
            {GLM_ICON} æ™ºè°±GLM-4
        </div>
        <div class="model-card-content">
            {final_display_glm}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # å­˜å‚¨å®Œæ•´ç»“æœ
    st.session_state.model_responses[user_input] = {
        "gemini": gemini_full_response,
        "glm": glm_full_response
    }
    
    # === 3. è¯­ä¹‰å¯¹æ¯” æµå¼è¾“å‡ºï¼ˆè§£å†³æˆªæ–­+ç©ºç™½è¡Œï¼‰ ===
    st.markdown('<div class="semantic-compare-header">ğŸ“Š è¯­ä¹‰å±‚é¢å¼‚åŒåˆ†æ</div>', unsafe_allow_html=True)
    semantic_placeholder = st.empty()
    semantic_full_response = ""
    
    # æµå¼ç”Ÿæˆè¯­ä¹‰æ€»ç»“ï¼ˆæ¸…ç†ç©ºç™½è¡Œï¼‰
    for chunk in generate_semantic_compare(gemini_full_response, glm_full_response, user_input, gemini_api_key):
        semantic_full_response += chunk
        # æ¸…ç†å†—ä½™æ¢è¡Œ + æ¸²æŸ“
        cleaned_semantic = clean_extra_newlines(semantic_full_response)
        display_semantic = cleaned_semantic.replace("\n", "<br>")
        semantic_placeholder.markdown(f"""
        <div class="semantic-card">
            <div class="semantic-content">
                {display_semantic}â–Œ
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“è¯­ä¹‰æ€»ç»“ï¼ˆæ¸…ç†ç©ºç™½è¡Œï¼Œç¡®ä¿å®Œæ•´ï¼‰
    final_semantic = clean_extra_newlines(semantic_full_response)
    final_display_semantic = final_semantic.replace("\n", "<br>")
    semantic_placeholder.markdown(f"""
    <div class="semantic-card">
        <div class="semantic-content">
            {final_display_semantic}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ·»åŠ åˆ°èŠå¤©è®°å½•
    combined_response = f"""
### åŒæ¨¡å‹è¯­ä¹‰åˆ†ææ€»ç»“ï¼š
{final_semantic}

### å®Œæ•´å›ç­”å‚è€ƒï¼š
- Gemini è¯¦ç»†åˆ†æï¼š{final_gemini[:200]}...
- æ™ºè°±GLM è¯¦ç»†åˆ†æï¼š{final_glm[:200]}...
    """
    st.session_state.messages.append({"role": "assistant", "content": combined_response})

# æ¸…ç©ºæŒ‰é’®ï¼ˆKimié£æ ¼ï¼‰
def clear_chat_history():
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¾·å›½è´¢ç¨ä¸“å®¶QFSã€‚è¯·é—®æ‚¨åœ¨ä¸­å›½ä¼ä¸šå‡ºæµ·è¿‡ç¨‹ä¸­é‡åˆ°äº†å“ªäº›è´¢åŠ¡ã€ç¨åŠ¡æˆ–å•†ä¸šèµ„è´¨æ–¹é¢çš„é—®é¢˜ï¼Ÿ"}
    ]
    st.session_state.model_responses = {}

st.button(
    'ğŸ§¹ æ¸…ç©ºèŠå¤©è®°å½•', 
    help="æ¸…é™¤æ‰€æœ‰å†å²å¯¹è¯", 
    key="clear_btn",
    on_click=clear_chat_history,
    class_="clear-btn"
)

# é—­åˆä¸»å®¹å™¨
st.markdown('</div>', unsafe_allow_html=True)
