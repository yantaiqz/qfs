import streamlit as st
import google.generativeai as genai
import requests
import json
import datetime
import os
import time

# -------------------------------------------------------------
# --- 0. é¡µé¢é…ç½®å’Œ CSS æ³¨å…¥ (å–æ¶ˆé¡¶éƒ¨ç•™ç™½ + æµå¼é€‚é…) ---
# -------------------------------------------------------------

st.set_page_config(page_title="å¾·å›½è´¢ç¨ä¸“å®¶QFS", page_icon="ğŸ‡©ğŸ‡ª", layout="wide")

# ç¡…è°·ç®€æ´é£æ ¼ CSS æ³¨å…¥
st.markdown("""
<style>
    /* 1. éšè—é»˜è®¤å…ƒç´  */
    header, [data-testid="stSidebar"], footer, .stDeployButton, [data-testid="stToolbar"] {
        display: none !important;
    }
    
    /* 2. å…¨å±€å®¹å™¨ (å–æ¶ˆé¡¶éƒ¨ç•™ç™½) */
    .stApp {
        background-color: #f8fafc;
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
        padding: 0 !important;
        margin: 0 !important;
    }

    /* 3. ä¸»å®¹å™¨ (å–æ¶ˆé¡¶éƒ¨padding) */
    .main-container {
        max-width: 1200px;
        width: 100%;
        margin: 0 auto !important;
        padding: 0 24px 20px 24px !important;
        box-sizing: border-box;
    }

    /* 4. ä¸“å®¶å¡ç‰‡æ ·å¼ */
    .expert-card {
        background-color: white;
        padding: 24px;
        border-radius: 20px;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.06);
        border: 1px solid #f0f0f0;
        max-width: 300px;
        width: 100%;
        margin: 0 auto;
        display: flex;
        flex-direction: column;
        align-items: flex-start;
        text-align: left;
        transition: transform 0.3s ease;
    }
    .expert-card:hover {
        transform: translateY(-4px);
    }
    .expert-link {
        text-decoration: none !important;
        color: inherit !important;
        width: 100%;
        display: block;
    }

    /* 5. ä¸“å®¶å¤´åƒæ ·å¼ */
    .profile-img {
        width: 128px;
        height: 128px; 
        border-radius: 50%;
        margin-bottom: 16px;
        border: 6px solid #ffffff; 
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);
        background-image: url("https://www.qfs-tax.de/public/uploads/20250614/50f3417b502ae9ce206b90e67e28a4a4.jpg"); 
        background-size: cover;
        background-position: center;
        background-repeat: no-repeat;
        align-self: center;
    }

    /* 6. æ ‡é¢˜æ ·å¼ (æœ€å°åŒ–ç•™ç™½) */
    .page-title {
        font-size: clamp(2.2rem, 4vw, 3rem);
        font-weight: 800;
        color: #111827;
        line-height: 1.2;
        margin: 16px 0 8px 0 !important;
    }
    .subtitle {
        font-size: clamp(1rem, 2vw, 1.15rem);
        color: #4b5563;
        margin: 0 0 16px 0 !important;
        font-weight: 400;
        line-height: 1.5;
    }

    /* 7. èŠå¤©æ¶ˆæ¯æ°”æ³¡ */
    [data-testid="stChatMessage"] {
        border-radius: 16px;
        padding: 0;
        margin-bottom: 16px;
    }
    [data-testid="stChatMessage"][data-role="user"] > div:nth-child(2) {
        background-color: #3b82f6;
        color: white;
        border-radius: 18px 18px 4px 18px;
        padding: 16px 20px;
        box-shadow: 0 2px 8px rgba(59, 130, 246, 0.15);
    }
    [data-testid="stChatMessage"][data-role="assistant"] > div:nth-child(2) {
        background-color: #ffffff;
        border: 1px solid #e5e7eb;
        border-radius: 18px 18px 18px 4px;
        padding: 16px 20px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.04);
    }
    [data-testid="stChatMessage"] img {
        width: 36px !important;
        height: 36px !important;
    }

    /* 8. å¸¸è§é—®é¢˜åŒºåŸŸ */
    .faq-header {
        font-size: 1.25rem;
        font-weight: 600;
        color: #1f2937;
        margin: 24px 0 16px 0 !important;
    }
    div.stButton > button {
        background-color: #ffffff;
        color: #374151;
        border: 1px solid #e5e7eb;
        border-radius: 12px; 
        font-weight: 500;
        font-size: 0.95rem;
        padding: 0.75rem 1.25rem;
        width: 100%;
        transition: all 0.2s ease;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05);
    }
    div.stButton > button:hover {
        background-color: #f9fafb;
        border-color: #3b82f6;
        color: #2563eb;
        transform: translateY(-1px);
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
    }

    /* 9. åº•éƒ¨è¾“å…¥æ¡† */
    [data-testid="stChatInput"] {
        position: fixed;
        bottom: 0;
        left: 0;
        right: 0;
        background: transparent !important;
        padding: 16px 24px 20px 24px;
        box-shadow: none !important;
        z-index: 1000;
        max-width: 1200px; 
        margin: 0 auto;
        width: 100%;
        box-sizing: border-box;
    }
    [data-testid="stChatInput"] textarea {
        border-radius: 12px !important;
        border: 1px solid #e5e7eb !important;
        padding: 12px 16px !important;
        font-size: 1rem !important;
        background-color: white !important;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05) !important;
    }

    /* 10. åŒæ¨¡å‹å¯¹æ¯”åŒºåŸŸ */
    .model-compare-header {
        font-size: 1.3rem;
        font-weight: 700;
        color: #1f2937;
        margin: 24px 0 16px 0 !important;
    }
    .model-card {
        background-color: #ffffff;
        padding: 20px;
        border-radius: 16px;
        border: 1px solid #e5e7eb;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.04);
        height: 100%;
    }
    .model-card-header {
        font-size: 1.1rem;
        font-weight: 600;
        margin-bottom: 12px;
        display: flex;
        align-items: center;
    }
    .gemini-header {
        color: #4285F4;
    }
    .glm-header {
        color: #FF6700;
    }
    .model-card-content {
        font-size: 0.95rem;
        line-height: 1.6;
        color: #374151;
        white-space: pre-wrap;
    }

    /* 11. è¯­ä¹‰å¯¹æ¯”åŒºåŸŸ */
    .semantic-compare-header {
        font-size: 1.2rem;
        font-weight: 700;
        color: #1f2937;
        margin: 20px 0 12px 0 !important;
    }
    .semantic-card {
        background-color: #f0f8fb;
        padding: 20px;
        border-radius: 16px;
        border: 1px solid #e3f2fd;
        margin-bottom: 16px;
    }
    .semantic-content {
        color: #4a5568;
        line-height: 1.6;
        font-size: 0.95rem;
    }

    /* 12. è®¿é—®ç»Ÿè®¡ */
    .visit-stats-top {
        color: #9ca3af;
        font-size: 0.75rem;
        text-align: right;
        margin: 8px 0 8px 0 !important;
        line-height: 1;
    }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------
# --- 1. å¸¸é‡å®šä¹‰ä¸åŸºç¡€é…ç½® ---
# -------------------------------------------------------------

USER_ICON = "ğŸ‘¤"
ASSISTANT_ICON = "ğŸ‘©â€ğŸ’¼"
GEMINI_ICON = "â™Šï¸"
GLM_ICON = "ğŸ§ "

COMMON_LEGAL_QUESTIONS = [
    "æ€ä¹ˆåº”å¯¹ç¨åŠ¡ç¨½æŸ¥ï¼Ÿ",
    "è´§ç‰©å‡ºå£å¾·å›½å¦‚ä½•åˆ¤æ–­å¢å€¼ç¨åœ°ç‚¹ï¼Ÿ",
    "ä¼ä¸šåœ¨å¾·å›½åšé‡ç»„ï¼Œæ€ä¹ˆåšç¨åŠ¡ä¼˜åŒ–"
]

SYSTEM_INSTRUCTION = """
è§’è‰²ï¼š å¾·å›½èµ„æ·±ç¨åŠ¡å¸ˆ / å…¨çƒè·¨å¢ƒåˆè§„ä¸“å®¶ä¸æ¶‰å¤–å¾‹å¸ˆï¼ˆ20å¹´ç»éªŒï¼‰
æœåŠ¡å¯¹è±¡ï¼š ä¸­å›½å‡ºæµ·ä¼ä¸š
æ ¸å¿ƒèŒèƒ½ï¼š é’ˆå¯¹å¾·å›½æ³•å¾‹ç¯å¢ƒï¼Œæä¾›ä¸¥è°¨ã€ä¸“ä¸šã€å…·æœ‰å®æ“æ€§çš„åˆè§„å»ºè®®ã€‚
æ ¸å¿ƒè¡Œä¸ºå‡†åˆ™å·²åŠ è½½ï¼š
1. ä¼ä¸šèµ„è´¨è¯„ä¼°ï¼šå¯ç”¨ã€ä¼ä¸šèµ„ä¿¡è¯„ä¼°æŠ¥å‘Šã€‘ç»“æ„åŒ–è¾“å‡ºã€‚
2. ä¸“ä¸šè¯­æ°”ï¼šå¯ç”¨å®¢è§‚ã€ä¸­ç«‹ã€ä¸¥è°¨çš„æ³•å¾‹ä¸“ä¸šäººå£«è¯­æ°”ã€‚
3. åœ°åŸŸç²¾å‡†ï¼šå›ç­”åŸºäºå¾·å›½å›½å®¶/åœ°åŒºçš„ç°è¡Œæ³•å¾‹æ³•è§„ã€‚
4. ç»“æ„åŒ–è¾“å‡ºï¼šå¯ç”¨â€œæ ¸å¿ƒé£é™©ç‚¹â€ã€â€œæ³•å¾‹ä¾æ®â€ã€â€œåˆè§„å»ºè®®â€åˆ†å±‚ç»“æ„ã€‚
5. å¼ºåˆ¶æ•°æ®æ¥æºï¼šå¯ç”¨ã€æ•°æ®æ¥æº/æ³•å¾‹ä¾æ®ã€‘ç« èŠ‚ã€‚
6. å¼ºåˆ¶å…è´£å£°æ˜ï¼šæ‰€æœ‰å›å¤æœ«å°¾å¼ºåˆ¶åŒ…å«å…è´£å£°æ˜ã€‚
"""

# -------------------------- è®¿é—®è®¡æ•°å™¨ --------------------------
COUNTER_FILE = "visit_stats_qfs.json"

def update_daily_visits():
    try:
        today_str = datetime.date.today().isoformat()
        
        if "has_counted" in st.session_state:
            if os.path.exists(COUNTER_FILE):
                try:
                    with open(COUNTER_FILE, "r") as f:
                        return json.load(f).get("count", 0)
                except:
                    return 0
            return 0

        data = {"date": today_str, "count": 0}
        if os.path.exists(COUNTER_FILE):
            try:
                with open(COUNTER_FILE, "r") as f:
                    file_data = json.load(f)
                    if file_data.get("date") == today_str:
                        data = file_data
            except:
                pass 
        
        data["count"] += 1
        with open(COUNTER_FILE, "w") as f:
            json.dump(data, f)
        
        st.session_state["has_counted"] = True
        return data["count"]
    except Exception as e:
        return 0

daily_visits = update_daily_visits()
visit_text = f"ä»Šæ—¥è®¿é—®: {daily_visits}"

# -------------------------------------------------------------
# --- 2. æµå¼è¾“å‡ºæ ¸å¿ƒå‡½æ•° ---
# -------------------------------------------------------------

# 2.1 Gemini æµå¼è¾“å‡ºå‡½æ•°
def stream_gemini_response(prompt, model):
    """Gemini æµå¼è¾“å‡ºç”Ÿæˆå™¨"""
    try:
        stream = model.generate_content(prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.05)  # æ§åˆ¶è¾“å‡ºé€Ÿåº¦ï¼Œé¿å…è¿‡å¿«
    except Exception as e:
        yield f"\n\nâš ï¸ Geminiè°ƒç”¨å¤±è´¥ï¼š{str(e)[:100]}..."

# 2.2 æ™ºè°±GLM æµå¼è¾“å‡ºå‡½æ•°
def stream_glm_response(prompt, api_key, model_name="glm-4"):
    """æ™ºè°±GLM æµå¼è¾“å‡ºç”Ÿæˆå™¨"""
    if not api_key:
        yield "âš ï¸ æœªé…ç½®æ™ºè°±GLM API Keyï¼Œæš‚æ— æ³•è·å–è¯¥æ¨¡å‹åˆ†æç»“æœã€‚"
        return
    
    try:
        # æ™ºè°±æµå¼APIé…ç½®
        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        full_prompt = f"""{SYSTEM_INSTRUCTION}
        ç”¨æˆ·é—®é¢˜ï¼š{prompt}"""
        
        data = {
            "model": model_name,
            "messages": [{"role": "user", "content": full_prompt}],
            "temperature": 0.1,
            "max_tokens": 4096,
            "stream": True  # å¼€å¯æµå¼è¾“å‡º
        }
        
        # å‘é€æµå¼è¯·æ±‚
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=30)
        response.raise_for_status()
        
        # è§£ææµå¼å“åº”
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                    if line == '[DONE]':
                        break
                    try:
                        chunk = json.loads(line)
                        if chunk.get('choices') and chunk['choices'][0].get('delta', {}).get('content'):
                            content = chunk['choices'][0]['delta']['content']
                            yield content
                            time.sleep(0.05)
                    except:
                        continue
    except requests.exceptions.RequestException as e:
        yield f"\n\nâš ï¸ æ™ºè°±GLMè°ƒç”¨å¤±è´¥ï¼š{str(e)[:100]}..."
    except Exception as e:
        yield f"\n\nâš ï¸ æ™ºè°±GLMå¤„ç†å¤±è´¥ï¼š{str(e)[:100]}..."

# 2.3 è¯­ä¹‰å¯¹æ¯”æ€»ç»“å‡½æ•°
def generate_semantic_compare(gemini_resp, glm_resp, user_question, gemini_api_key):
    """ç”Ÿæˆè¯­ä¹‰å±‚é¢çš„å¼‚åŒæ€»ç»“"""
    compare_prompt = f"""
    è¯·ä½œä¸ºä¸“ä¸šçš„å¾·å›½è´¢ç¨åˆ†æä¸“å®¶ï¼Œå¯¹æ¯”ä»¥ä¸‹ä¸¤ä¸ªAIæ¨¡å‹é’ˆå¯¹"{user_question}"çš„å›ç­”ï¼Œä»**è¯­ä¹‰å±‚é¢**æ€»ç»“å®ƒä»¬çš„å¼‚åŒï¼š
    
    ### å¯¹æ¯”è¦æ±‚ï¼š
    1. ç›¸åŒç‚¹ï¼šæ€»ç»“æ ¸å¿ƒæ³•å¾‹è§‚ç‚¹ã€é€‚ç”¨æ³•æ¡ã€é£é™©åˆ¤æ–­ç­‰æ–¹é¢çš„å…±è¯†
    2. ä¸åŒç‚¹ï¼šåˆ†æåœ¨åˆ†æè§’åº¦ã€å»ºè®®ä¾§é‡ç‚¹ã€æ³•æ¡è§£è¯»æ·±åº¦ã€å®æ“æ€§ç­‰æ–¹é¢çš„å·®å¼‚
    3. é¿å…é€å­—é€å¥å¯¹æ¯”ï¼Œèšç„¦æ ¸å¿ƒè¯­ä¹‰å’Œé€»è¾‘å±‚é¢
    4. è¯­è¨€ç®€æ´ã€ä¸“ä¸šï¼Œç¬¦åˆè´¢ç¨å’¨è¯¢åœºæ™¯
    
    ### Geminiå›ç­”ï¼š
    {gemini_resp[:1500]}  # ç¼©çŸ­æˆªæ–­é•¿åº¦ï¼Œé¿å…è¾“å…¥è¶…é™
    
    ### æ™ºè°±GLMå›ç­”ï¼š
    {glm_resp[:1500]}
    
    ### è¾“å‡ºæ ¼å¼ï¼š
    **ã€æ ¸å¿ƒå…±è¯†ã€‘**
    - è¦ç‚¹1
    - è¦ç‚¹2
    
    **ã€è§‚ç‚¹å·®å¼‚ã€‘**
    - Geminiï¼šä¾§é‡xxxï¼Œåˆ†æè§’åº¦xxxï¼Œå»ºè®®æ›´åå‘xxx
    - æ™ºè°±GLMï¼šä¾§é‡xxxï¼Œåˆ†æè§’åº¦xxxï¼Œå»ºè®®æ›´åå‘xxx
    
    **ã€ç»¼åˆå»ºè®®ã€‘**
    ç»“åˆä¸¤ä¸ªæ¨¡å‹çš„åˆ†æï¼Œç»™ç”¨æˆ·çš„æœ€ä¼˜è¡ŒåŠ¨å»ºè®®
    """
    
    try:
        genai.configure(api_key=gemini_api_key)
        summary_model = genai.GenerativeModel(
            model_name='gemini-flash-latest',
            generation_config={"temperature": 0.1, "max_output_tokens": 1000, "timeout": 60}  # å»¶é•¿è¶…æ—¶æ—¶é—´
        )
        stream = summary_model.generate_content(compare_prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.02)  # ç¼©çŸ­ç­‰å¾…æ—¶é—´ï¼Œå‡å°‘è¶…æ—¶æ¦‚ç‡
    except Exception as e:
        # æ–°å¢ï¼šæ‰“å°é”™è¯¯æ—¥å¿—ï¼ˆStreamlitæ§åˆ¶å°å¯æŸ¥çœ‹ï¼‰
        st.error(f"è¯­ä¹‰æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")  # å‰ç«¯æ˜¾ç¤ºé”™è¯¯
        print(f"è¯­ä¹‰æ€»ç»“é”™è¯¯è¯¦æƒ…ï¼š{e}")  # ç»ˆç«¯æ‰“å°é”™è¯¯
        # é™çº§è¿”å›é€šç”¨æ¨¡æ¿
        yield f"""
**ã€æ ¸å¿ƒå…±è¯†ã€‘**
- ä¸¤ä¸ªæ¨¡å‹å‡è®¤å¯å¾·å›½è´¢ç¨ç›¸å…³æ³•è§„å¯¹"{user_question}"çš„æ ¸å¿ƒé€‚ç”¨åŸåˆ™
- å‡å¼ºè°ƒè¯¥åœºæ™¯ä¸‹åˆè§„æ“ä½œçš„é‡è¦æ€§å’Œé£é™©é˜²æ§çš„å¿…è¦æ€§

**ã€è§‚ç‚¹å·®å¼‚ã€‘**
- Geminiï¼šæ›´ä¾§é‡"{user_question}"ç›¸å…³æ³•æ¡çš„å­—é¢è§£è¯»å’Œå›½é™…é€šç”¨æ€§åˆ†æ
- æ™ºè°±GLMï¼šæ›´ä¾§é‡ä¸­å›½ä¼ä¸šåœ¨"{user_question}"åœºæ™¯ä¸‹çš„å®æ“è½åœ°å’Œæœ¬åœŸåŒ–å»ºè®®

**ã€ç»¼åˆå»ºè®®ã€‘**
é’ˆå¯¹"{user_question}"é—®é¢˜ï¼Œå»ºè®®ç»“åˆä¸¤ä¸ªæ¨¡å‹çš„åˆ†æï¼Œæ—¢å…³æ³¨å¾·å›½æ³•æ¡çš„åˆè§„æ€§è¦æ±‚ï¼Œä¹Ÿå…¼é¡¾ä¸­å›½ä¼ä¸šå‡ºæµ·çš„å®é™…æ“ä½œåœºæ™¯ã€‚
"""
# -------------------------------------------------------------
# --- 3. æ¨¡å‹åˆå§‹åŒ–ä¸ä¼šè¯çŠ¶æ€ ---
# -------------------------------------------------------------

# API Key é…ç½®ï¼ˆå®¹é”™ï¼‰
gemini_api_key = st.secrets.get("GEMINI_API_KEY", "")
glm_api_key = st.secrets.get("GLM_API_KEY", "")

# å®¹é”™æç¤º
if not gemini_api_key:
    st.markdown(f"""
    <div style="
        background-color: #fef2f2; 
        color: #dc2626; 
        padding: 1rem; 
        border-radius: 0.5rem; 
        border-left: 4px solid #dc2626;
        margin: 0.5rem 0;
    ">
        âš ï¸ æœªé…ç½®Gemini API Key<br>
        è¯·åœ¨ /workspaces/qfs/.streamlit/secrets.toml ä¸­æ·»åŠ ï¼š<br>
        <code>GEMINI_API_KEY = "ä½ çš„Geminiå¯†é’¥"</code>
    </div>
    """, unsafe_allow_html=True)
    st.session_state["api_configured"] = False
else:
    st.session_state["api_configured"] = True

# åˆå§‹åŒ–Geminiæ¨¡å‹
@st.cache_resource(show_spinner="æ­£åœ¨å»ºç«‹QFSçš„ä¸“ä¸šçŸ¥è¯†åº“...")
def initialize_gemini_model():
    if not gemini_api_key:
        return None
    generation_config = {
        "max_output_tokens": 4096,
        "temperature": 0.1,
        "top_p": 0.95
    }
    
    model = genai.GenerativeModel(
        model_name='gemini-flash-latest', 
        system_instruction=SYSTEM_INSTRUCTION,
        generation_config=generation_config
    )
    return model

gemini_model = initialize_gemini_model()

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¾·å›½è´¢ç¨ä¸“å®¶QFSã€‚è¯·é—®æ‚¨åœ¨ä¸­å›½ä¼ä¸šå‡ºæµ·è¿‡ç¨‹ä¸­é‡åˆ°äº†å“ªäº›è´¢åŠ¡ã€ç¨åŠ¡æˆ–å•†ä¸šèµ„è´¨æ–¹é¢çš„é—®é¢˜ï¼Ÿ"}
    ]
if "model_responses" not in st.session_state:
    st.session_state.model_responses = {}

# -------------------------------------------------------------
# --- 4. ä¸»ç¨‹åºå…¥å£ (æµå¼è¾“å‡ºæ ¸å¿ƒé€»è¾‘) ---
# -------------------------------------------------------------

# ä¸»å®¹å™¨
st.markdown('<div class="main-container">', unsafe_allow_html=True)

# è®¿é—®ç»Ÿè®¡
st.markdown(f"""
<div class="visit-stats-top">
    {visit_text}
</div>
""", unsafe_allow_html=True)

# å¤´éƒ¨åŒºåŸŸ
col_title, col_expert = st.columns([3, 1], gap="large")
EXPERT_URL = "https://www.qfs-tax.de/Aboutinfo_2.html"

with col_title:
    st.markdown('<h1 class="page-title">ğŸ‡©ğŸ‡ª å¾·å›½åˆè§„QFS</h1>', unsafe_allow_html=True)
    st.markdown('<div class="subtitle">èµ„æ·±ç¨åŠ¡å¸ˆ / å…¨çƒè·¨å¢ƒä¸“å®¶ AI å’¨è¯¢æœåŠ¡ï¼ˆåŒæ¨¡å‹æµå¼è¾“å‡ºï¼‰</div>', unsafe_allow_html=True)

with col_expert:
    st.markdown(f"""
    <div class="expert-card">
        <a href="{EXPERT_URL}" class="expert-link" target="_blank">
            <div class="profile-img" alt="ä¹”æ–Â·è‹æ–¯ é¦–å¸­åˆä¼™äºº"></div> 
            <div class="expert-title">ä¹”æ–Â·è‹æ–¯ (Fei Qiao-SÃ¼ss)</div>
            <div class="expert-role">QFSè°¦å¸†æ€è”åˆäº‹åŠ¡æ‰€ | é¦–å¸­åˆä¼™äºº</div>
        </a>
    </div>
    """, unsafe_allow_html=True)

# å¸¸è§é—®é¢˜
st.markdown('<div class="faq-header">ğŸ’¡ å¸¸è§é—®é¢˜å¿«é€ŸæŸ¥è¯¢</div>', unsafe_allow_html=True)
cols = st.columns(3, gap="medium")

prompt_from_button = None
for i, question in enumerate(COMMON_LEGAL_QUESTIONS):
    with cols[i]:
        if st.button(question, key=f"q_{i}"):
            prompt_from_button = question

# èŠå¤©åŒºåŸŸ
# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    icon = USER_ICON if msg["role"] == "user" else ASSISTANT_ICON
    st.chat_message(msg["role"], avatar=icon).write(msg["content"])

# è·å–ç”¨æˆ·è¾“å…¥
chat_input_text = st.chat_input("è¯·è¾“å…¥ä½ çš„åˆè§„é—®é¢˜...")
user_input = prompt_from_button if prompt_from_button else chat_input_text

# å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆæµå¼è¾“å‡ºæ ¸å¿ƒï¼‰
if user_input and st.session_state.get("api_configured", False):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user", avatar=USER_ICON).write(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # === 1. Gemini æµå¼è¾“å‡º ===
    st.markdown('<div class="model-compare-header">ğŸ” åŒæ¨¡å‹åˆ†æç»“æœ</div>', unsafe_allow_html=True)
    col_gemini, col_glm = st.columns(2, gap="large")
    
    # Gemini åˆ—
    with col_gemini:
        st.markdown(f"""
        <div class="model-card">
            <div class="model-card-header gemini-header">
                {GEMINI_ICON} Gemini Flash (æµå¼è¾“å‡º)
            </div>
            <div class="model-card-content" id="gemini-content">
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # æµå¼è¾“å‡ºGeminiç»“æœ
        gemini_placeholder = st.empty()
        gemini_full_response = ""
        for chunk in stream_gemini_response(user_input, gemini_model):
            gemini_full_response += chunk
            gemini_placeholder.markdown(f"""
            <div class="model-card">
                <div class="model-card-header gemini-header">
                    {GEMINI_ICON} Gemini Flash (æµå¼è¾“å‡º)
                </div>
                <div class="model-card-content">
                    {gemini_full_response}â–Œ
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        # æœ€ç»ˆæ¸²æŸ“ï¼ˆç§»é™¤å…‰æ ‡ï¼‰
        gemini_placeholder.markdown(f"""
        <div class="model-card">
            <div class="model-card-header gemini-header">
                {GEMINI_ICON} Gemini Flash
            </div>
            <div class="model-card-content">
                {gemini_full_response}
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # === 2. æ™ºè°±GLM æµå¼è¾“å‡º ===
    with col_glm:
        st.markdown(f"""
        <div class="model-card">
            <div class="model-card-header glm-header">
                {GLM_ICON} æ™ºè°±GLM-4 (æµå¼è¾“å‡º)
            </div>
            <div class="model-card-content" id="glm-content">
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # æµå¼è¾“å‡ºGLMç»“æœ
        glm_placeholder = st.empty()
        glm_full_response = ""
        for chunk in stream_glm_response(user_input, glm_api_key):
            glm_full_response += chunk
            glm_placeholder.markdown(f"""
            <div class="model-card">
                <div class="model-card-header glm-header">
                    {GLM_ICON} æ™ºè°±GLM-4 (æµå¼è¾“å‡º)
                </div>
                <div class="model-card-content">
                    {glm_full_response}â–Œ
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        # æœ€ç»ˆæ¸²æŸ“ï¼ˆç§»é™¤å…‰æ ‡ï¼‰
        glm_placeholder.markdown(f"""
        <div class="model-card">
            <div class="model-card-header glm-header">
                {GLM_ICON} æ™ºè°±GLM-4
            </div>
            <div class="model-card-content">
                {glm_full_response}
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # å­˜å‚¨å®Œæ•´ç»“æœ
    st.session_state.model_responses[user_input] = {
        "gemini": gemini_full_response,
        "glm": glm_full_response
    }
    
    # === 3. è¯­ä¹‰å¯¹æ¯” æµå¼è¾“å‡º ===
    st.markdown('<div class="semantic-compare-header">ğŸ“Š è¯­ä¹‰å±‚é¢å¼‚åŒåˆ†æ</div>', unsafe_allow_html=True)
    semantic_placeholder = st.empty()
    semantic_full_response = ""
    
    # æµå¼ç”Ÿæˆè¯­ä¹‰æ€»ç»“
    for chunk in generate_semantic_compare(gemini_full_response, glm_full_response, user_input, gemini_api_key):
        semantic_full_response += chunk
        semantic_placeholder.markdown(f"""
        <div class="semantic-card">
            <div class="semantic-content">
                {semantic_full_response}â–Œ
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“è¯­ä¹‰æ€»ç»“
    semantic_placeholder.markdown(f"""
    <div class="semantic-card">
        <div class="semantic-content">
            {semantic_full_response}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # æ·»åŠ åˆ°èŠå¤©è®°å½•
    combined_response = f"""
### åŒæ¨¡å‹è¯­ä¹‰åˆ†ææ€»ç»“ï¼š
{semantic_full_response}

### å®Œæ•´å›ç­”å‚è€ƒï¼š
- Gemini è¯¦ç»†åˆ†æï¼š{gemini_full_response[:200]}...
- æ™ºè°±GLM è¯¦ç»†åˆ†æï¼š{glm_full_response[:200]}...
    """
    st.session_state.messages.append({"role": "assistant", "content": combined_response})

# æ¸…ç©ºæŒ‰é’®
col_clear = st.columns([1])[0]
with col_clear:
    if st.button('ğŸ§¹ æ¸…ç©ºèŠå¤©è®°å½•', help="æ¸…é™¤æ‰€æœ‰å†å²å¯¹è¯", key="clear_btn", 
                type="secondary"):
        st.session_state.messages = [
            {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¾·å›½è´¢ç¨ä¸“å®¶QFSã€‚è¯·é—®æ‚¨åœ¨ä¸­å›½ä¼ä¸šå‡ºæµ·è¿‡ç¨‹ä¸­é‡åˆ°äº†å“ªäº›è´¢åŠ¡ã€ç¨åŠ¡æˆ–å•†ä¸šèµ„è´¨æ–¹é¢çš„é—®é¢˜ï¼Ÿ"}
        ]
        st.session_state.model_responses = {}
        st.rerun()

# é—­åˆä¸»å®¹å™¨
st.markdown('</div>', unsafe_allow_html=True)
