import streamlit as st
import google.generativeai as genai
import requests
import json
import datetime
import os
import time
import re

# -------------------------------------------------------------
# --- 0. é¡µé¢é…ç½®å’Œ CSS æ³¨å…¥ (Legalon Tech é£æ ¼) ---
# -------------------------------------------------------------

st.set_page_config(
    page_title="å¾·å›½è´¢ç¨ä¸“å®¶QFS", 
    page_icon="ğŸ‡©ğŸ‡ª", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Legalon Tech é£æ ¼æ ¸å¿ƒ CSS
st.markdown("""
<style>
    /* 1. å…¨å±€å­—ä½“ä¸é‡ç½® */
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap');
    
    * {
        font-family: 'Noto Sans SC', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif !important;
        box-sizing: border-box;
    }
    
    html, body, [data-testid="stAppViewContainer"] {
        background-color: #ffffff !important;
    }

    /* 2. æ ¸å¿ƒï¼šå»é™¤é¡¶éƒ¨ç©ºç™½ä¸éšè—é»˜è®¤å…ƒç´  */
    [data-testid="stHeader"], [data-testid="stToolbar"], footer, .stDeployButton {
        display: none !important;
    }
    
    /* è°ƒæ•´ä¸»å®¹å™¨ Paddingï¼Œæ¶ˆé™¤é¡¶éƒ¨å¤§ç‰‡ç•™ç™½ */
    .block-container {
        padding-top: 1.5rem !important;
        padding-bottom: 8rem !important;
        max-width: 900px !important;
    }

    /* 3. æ ‡é¢˜åŒºåŸŸ (Legalon é£æ ¼ï¼šç®€æ´ã€æ·±è“) */
    .page-title {
        font-size: 2.2rem !important;
        font-weight: 700 !important;
        color: #003366 !important; /* Legalon Navy Blue */
        margin: 0 0 8px 0 !important;
        text-align: center !important;
        letter-spacing: -0.5px !important;
    }
    .subtitle {
        font-size: 1rem !important;
        color: #666666 !important;
        margin: 0 0 40px 0 !important;
        text-align: center !important;
        font-weight: 400 !important;
    }

    /* 4. èŠå¤©æ°”æ³¡ä¼˜åŒ– */
    [data-testid="stChatMessage"] {
        padding: 0 !important;
        margin-bottom: 24px !important;
    }
    /* ç”¨æˆ·æ°”æ³¡ */
    [data-testid="stChatMessage"][data-role="user"] > div:nth-child(2) {
        background-color: #003366 !important; /* æ·±è“ */
        color: white !important;
        border-radius: 12px 12px 2px 12px !important;
        padding: 16px 24px !important;
        font-size: 0.95rem !important;
        box-shadow: 0 2px 5px rgba(0,51,102,0.1) !important;
    }
    /* AI æ°”æ³¡ */
    [data-testid="stChatMessage"][data-role="assistant"] > div:nth-child(2) {
        background-color: transparent !important;
        padding: 0 !important;
        color: #1a1a1a !important;
    }
    
    /* å¤´åƒæ ·å¼ */
    [data-testid="stChatMessage"] .st-emotion-cache-1p1m4ay, 
    [data-testid="stChatMessage"] .st-emotion-cache-p4 micv {
        width: 36px !important;
        height: 36px !important;
        border: 1px solid #e0e0e0;
    }

    /* 5. å¡ç‰‡å¼è®¾è®¡ (é€šç”¨) */
    .result-card {
        background-color: #ffffff !important;
        border: 1px solid #e5e7eb !important;
        border-radius: 8px !important;
        margin-bottom: 20px !important;
        overflow: hidden !important;
        transition: box-shadow 0.2s ease;
    }
    .result-card:hover {
        box-shadow: 0 4px 12px rgba(0,0,0,0.05) !important;
    }
    
    .card-header {
        padding: 12px 20px !important;
        font-size: 0.9rem !important;
        font-weight: 600 !important;
        display: flex !important;
        align-items: center !important;
        border-bottom: 1px solid #f0f2f5 !important;
        background-color: #f8fafc !important; /* ææ·¡çš„ç°è“ */
    }
    .gemini-bg { color: #1a73e8 !important; }
    .glm-bg { color: #f59e0b !important; }
    
    .card-content {
        padding: 20px !important;
        font-size: 0.95rem !important;
        line-height: 1.7 !important;
        color: #333333 !important;
    }

    /* 6. è¯­ä¹‰åˆ†æå¡ç‰‡ (é‡ç‚¹ä¼˜åŒ–) */
    .semantic-card {
        background-color: #f0f7ff !important; /* ææ·¡çš„ Legalon è“èƒŒæ™¯ */
        border: 1px solid #cfe2ff !important;
        border-radius: 8px !important;
        margin-top: 24px !important;
    }
    .semantic-content strong {
        display: block !important;
        color: #003366 !important;
        font-size: 1rem !important;
        margin-top: 16px !important;
        margin-bottom: 8px !important;
        padding-bottom: 4px !important;
        border-bottom: 1px dashed #cfe2ff !important;
    }
    .semantic-content strong:first-child {
        margin-top: 0 !important;
    }

    /* 7. è¾“å…¥æ¡†ä¸æŒ‰é’® */
    [data-testid="stChatInput"] {
        padding-bottom: 20px !important;
    }
    div.stButton > button {
        border-radius: 6px !important;
        border: 1px solid #e5e7eb !important;
        background-color: white !important;
        color: #666 !important;
        font-weight: 500 !important;
        transition: all 0.2s !important;
    }
    div.stButton > button:hover {
        border-color: #003366 !important;
        color: #003366 !important;
        background-color: #f0f7ff !important;
    }

    /* Markdown åˆ—è¡¨ä¿®æ­£ */
    ul { margin-left: 20px !important; padding-left: 0 !important; }
    li { margin-bottom: 6px !important; }
    
    /* å¸¸ç”¨é—®é¢˜åŒºåŸŸ */
    .faq-header {
        font-size: 0.85rem !important;
        color: #888 !important;
        margin: 30px 0 10px 0 !important;
        text-transform: uppercase !important;
        letter-spacing: 1px !important;
    }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------
# --- å·¥å…·å‡½æ•° ---
# -------------------------------------------------------------
def clean_extra_newlines(text):
    """æ¸…ç†å†—ä½™æ¢è¡Œ/ç©ºæ ¼"""
    cleaned = re.sub(r'\n{2,}', '\n', text)
    cleaned = re.sub(r'ã€€+', '', cleaned)
    cleaned = cleaned.strip('\n')
    return cleaned

def complete_markdown_syntax(text):
    """ç®€å•è¡¥å…¨æœªé—­åˆçš„ Markdown"""
    if text.count("**") % 2 != 0: text += "**"
    return text

def markdown_to_html(text):
    """å°† Markdown è½¬ä¸º HTMLï¼Œä¸“é—¨ä¼˜åŒ–æ ‡é¢˜å’Œåˆ—è¡¨"""
    text = complete_markdown_syntax(text)
    # æ›¿æ¢åŠ ç²—
    text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', text)
    
    lines = text.split("\n")
    html_lines = []
    in_list = False
    
    for line in lines:
        line = line.strip()
        if not line: continue
        
        if line.startswith("- "):
            if not in_list:
                html_lines.append("<ul>")
                in_list = True
            html_lines.append(f"<li>{line[2:]}</li>")
        else:
            if in_list:
                html_lines.append("</ul>")
                in_list = False
            html_lines.append(f"<p>{line}</p>")
            
    if in_list: html_lines.append("</ul>")
    return "\n".join(html_lines)

# -------------------------------------------------------------
# --- 1. é…ç½®ä¸åˆå§‹åŒ– ---
# -------------------------------------------------------------
USER_ICON = "ğŸ‘¤"
ASSISTANT_ICON = "âš–ï¸"
GEMINI_ICON = "â™Šï¸"
GLM_ICON = "ğŸ§ "

COMMON_LEGAL_QUESTIONS = [
    "æ€ä¹ˆåº”å¯¹ç¨åŠ¡ç¨½æŸ¥ï¼Ÿ",
    "è´§ç‰©å‡ºå£å¾·å›½å¦‚ä½•åˆ¤æ–­å¢å€¼ç¨åœ°ç‚¹ï¼Ÿ",
    "ä¼ä¸šåœ¨å¾·å›½åšé‡ç»„ï¼Œæ€ä¹ˆåšç¨åŠ¡ä¼˜åŒ–"
]

SYSTEM_INSTRUCTION = """
è§’è‰²ï¼šå¾·å›½èµ„æ·±ç¨åŠ¡å¸ˆï¼ˆ20å¹´è·¨å¢ƒåˆè§„ç»éªŒï¼‰
æœåŠ¡å¯¹è±¡ï¼šä¸­å›½å‡ºæµ·ä¼ä¸š
æ ¸å¿ƒè¦æ±‚ï¼š
1. åŸºäºå¾·å›½ç°è¡Œæ³•å¾‹æ³•è§„ï¼Œæä¾›ä¸“ä¸šã€ä¸¥è°¨å»ºè®®ï¼›
2. ç»“æ„åŒ–è¾“å‡ºï¼šæ ¸å¿ƒé£é™© -> æ³•å¾‹ä¾æ®(å…·ä½“æ³•æ¡) -> åˆè§„å»ºè®® -> å…è´£å£°æ˜ï¼›
3. æ’ç‰ˆç®€æ´ã€‚
"""

# API Config
gemini_api_key = st.secrets.get("GEMINI_API_KEY", "")
glm_api_key = st.secrets.get("GLM_API_KEY", "")

if not gemini_api_key:
    st.warning("âš ï¸ æœªé…ç½® Gemini API Key")
    st.session_state["api_configured"] = False
else:
    st.session_state["api_configured"] = True

@st.cache_resource
def initialize_gemini_model():
    if not gemini_api_key: return None
    return genai.GenerativeModel(
        model_name='gemini-flash-latest', 
        system_instruction=SYSTEM_INSTRUCTION,
        generation_config={"temperature": 0.1}
    )

gemini_model = initialize_gemini_model()

if "messages" not in st.session_state:
    st.session_state.messages = []
if "model_responses" not in st.session_state:
    st.session_state.model_responses = {}

# -------------------------------------------------------------
# --- 2. æµå¼å¤„ç†å‡½æ•° ---
# -------------------------------------------------------------
def stream_gemini_response(prompt, model):
    try:
        stream = model.generate_content(prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.02)
    except Exception as e:
        yield f"Gemini Error: {str(e)}"

def stream_glm_response(prompt, api_key):
    if not api_key:
        yield "æœªé…ç½®æ™ºè°± API Key"
        return
    try:
        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        data = {
            "model": "glm-4",
            "messages": [{"role": "user", "content": SYSTEM_INSTRUCTION + "\n" + prompt}],
            "stream": True
        }
        resp = requests.post(url, headers=headers, json=data, stream=True)
        for line in resp.iter_lines():
            if line:
                line = line.decode('utf-8').replace('data: ', '')
                if line == '[DONE]': break
                try:
                    chunk = json.loads(line)
                    content = chunk['choices'][0]['delta'].get('content', '')
                    if content: yield content
                except: pass
    except Exception as e:
        yield f"GLM Error: {str(e)}"

def generate_semantic_compare(gemini_resp, glm_resp, user_question, gemini_api_key):
    # å¼ºåˆ¶æ ¼å¼ Prompt
    compare_prompt = f"""
    ä½œä¸ºä¸“å®¶ï¼Œå¯¹æ¯”ä»¥ä¸‹ä¸¤ä¸ªå…³äº"{user_question}"çš„æ³•å¾‹å›ç­”ã€‚
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼è¾“å‡ºï¼ˆä¸è¦æ·»åŠ å…¶ä»–å¼€åœºç™½ï¼‰ï¼š

    **æ ¸å¿ƒå…±è¯†**
    - [å…±è¯†ç‚¹1]
    - [å…±è¯†ç‚¹2]

    **è§‚ç‚¹å·®å¼‚**
    - Geminiï¼š[ä¾§é‡ç‚¹]
    - æ™ºè°±GLMï¼š[ä¾§é‡ç‚¹]

    **ç»¼åˆå»ºè®®**
    [ä½ çš„ä¸“ä¸šåˆè§„å»ºè®®]

    ---
    å›ç­”A (Gemini): {gemini_resp[:1500]}
    å›ç­”B (GLM): {glm_resp[:1500]}
    """
    try:
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('gemini-flash-latest')
        stream = model.generate_content(compare_prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.02)
    except:
        yield "**åˆ†æå¤±è´¥**\næ— æ³•ç”Ÿæˆå¯¹æ¯”ç»“æœã€‚"

# -------------------------------------------------------------
# --- 3. é¡µé¢æ¸²æŸ“é€»è¾‘ ---
# -------------------------------------------------------------

# æ ‡é¢˜ (Legalon é£æ ¼)
st.markdown('<h1 class="page-title">QFS Global Compliance</h1>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">Powered by Gemini & GLM-4 Â· å¾·å›½è´¢ç¨åˆè§„å¼•æ“</div>', unsafe_allow_html=True)

# å†å²è®°å½•å›æ˜¾
for msg in st.session_state.messages:
    st.chat_message(msg["role"], avatar=USER_ICON if msg["role"] == "user" else ASSISTANT_ICON).write(msg["content"])

# å¸¸è§é—®é¢˜åŒº (ä»…å½“æ²¡æœ‰å†å²è®°å½•æ—¶æ˜¾ç¤ºï¼Œä¿æŒç•Œé¢æ•´æ´)
prompt_from_button = None
if not st.session_state.messages:
    st.markdown('<div class="faq-header">å¸¸è§åˆè§„å’¨è¯¢</div>', unsafe_allow_html=True)
    cols = st.columns(3)
    for i, q in enumerate(COMMON_LEGAL_QUESTIONS):
        if cols[i % 3].button(q, key=f"btn_{i}", use_container_width=True):
            prompt_from_button = q

# å¤„ç†è¾“å…¥
chat_input = st.chat_input("è¯·è¾“å…¥å…·ä½“çš„å¾·å›½è´¢ç¨é—®é¢˜...")
user_query = prompt_from_button or chat_input

if user_query and st.session_state.get("api_configured"):
    # 1. æ˜¾ç¤ºç”¨æˆ·æé—®
    st.chat_message("user", avatar=USER_ICON).markdown(user_query)
    st.session_state.messages.append({"role": "user", "content": user_query})

    # 2. å ä½å®¹å™¨
    st.markdown("### âš–ï¸ AI åˆè§„åˆ†æ")
    
    # Gemini å®¹å™¨
    gemini_container = st.empty()
    # GLM å®¹å™¨
    glm_container = st.empty()
    # è¯­ä¹‰å¯¹æ¯”å®¹å™¨
    semantic_container = st.empty()

    # --- æ‰§è¡Œ Gemini ---
    gemini_text = ""
    for chunk in stream_gemini_response(user_query, gemini_model):
        gemini_text += chunk
        html = markdown_to_html(clean_extra_newlines(gemini_text))
        gemini_container.markdown(f"""
        <div class="result-card">
            <div class="card-header gemini-bg">{GEMINI_ICON} Gemini Flash æ³•å¾‹æ„è§</div>
            <div class="card-content">{html}</div>
        </div>
        """, unsafe_allow_html=True)

    # --- æ‰§è¡Œ GLM ---
    glm_text = ""
    for chunk in stream_glm_response(user_query, glm_api_key):
        glm_text += chunk
        html = markdown_to_html(clean_extra_newlines(glm_text))
        glm_container.markdown(f"""
        <div class="result-card">
            <div class="card-header glm-bg">{GLM_ICON} æ™ºè°± GLM-4 æ³•å¾‹æ„è§</div>
            <div class="card-content">{html}</div>
        </div>
        """, unsafe_allow_html=True)

    # --- æ‰§è¡Œ è¯­ä¹‰å¯¹æ¯” ---
    semantic_text = ""
    for chunk in generate_semantic_compare(gemini_text, glm_text, user_query, gemini_api_key):
        semantic_text += chunk
        html = markdown_to_html(clean_extra_newlines(semantic_text))
        semantic_container.markdown(f"""
        <div class="result-card semantic-card">
            <div class="card-header" style="background:none; border:none; color:#003366;">
                ğŸ“Š æ·±åº¦è¯­ä¹‰å¼‚åŒåˆ†æ
            </div>
            <div class="card-content semantic-content">{html}</div>
        </div>
        """, unsafe_allow_html=True)

    # è®°å½•åˆ°å†å²
    full_record = f"**åŒæ¨¡å‹åˆ†æå®Œæˆ**\n\næŸ¥çœ‹ä¸Šæ–¹å¡ç‰‡è·å– Gemini ä¸ GLM çš„è¯¦ç»†æ³•å¾‹æ„è§å¯¹æ¯”ã€‚\n\n**æ€»ç»“å»ºè®®**ï¼š\n{semantic_text}"
    st.session_state.messages.append({"role": "assistant", "content": full_record})

# åº•éƒ¨æ¸…ç©ºæŒ‰é’®
if st.session_state.messages:
    if st.button('é‡ç½®å¯¹è¯', key="reset_btn"):
        st.session_state.messages = []
        st.rerun()
