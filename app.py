import streamlit as st
import google.generativeai as genai
import requests
import json
import datetime
import os
import time
import re

# -------------------------------------------------------------
# --- 0. é¡µé¢é…ç½®å’Œ CSS æ³¨å…¥ (æ¨¡ä»¿legalontech.jpé£æ ¼) ---
# -------------------------------------------------------------

st.set_page_config(
    page_title="å¾·å›½è´¢ç¨ä¸“å®¶QFS", 
    page_icon="ğŸ‡©ğŸ‡ª", 
    layout="wide",
    initial_sidebar_state="collapsed"
)

# legalontech.jp é£æ ¼æ ¸å¿ƒ CSS - æç®€ã€ä¸“ä¸šã€æ— å†—ä½™ç©ºç™½
st.markdown("""
<style>
    /* 1. å…¨å±€é‡ç½® - å½»åº•ç§»é™¤æ‰€æœ‰é»˜è®¤è¾¹è· */
    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }
    
    /* æ ¸å¿ƒï¼šç§»é™¤æ‰€æœ‰é¡¶éƒ¨ç©ºç™½ */
    html, body {
        height: 100%;
        width: 100%;
        margin: 0 !important;
        padding: 0 !important;
    }
    
    [data-testid="stAppViewContainer"], [data-testid="stMain"], .stApp {
        padding: 0 !important;
        margin: 0 !important;
        background-color: #f9f9f9 !important; /* legalontech æµ…ç°èƒŒæ™¯ */
        font-family: 'Helvetica Neue', Arial, sans-serif !important;
    }

    /* 2. éšè—æ‰€æœ‰ Streamlit é»˜è®¤å…ƒç´  */
    header, [data-testid="stSidebar"], footer, .stDeployButton, [data-testid="stToolbar"],
    [data-testid="stDecoration"], [data-testid="stStatusWidget"], [data-testid="stHeader"],
    [data-testid="stVerticalBlock"] > [data-testid="stVerticalBlock"]:first-child {
        display: none !important;
    }

    /* 3. ä¸»å®¹å™¨ - legalontech é£æ ¼çª„ç‰ˆå±…ä¸­ */
    .main-container {
        max-width: 900px !important;
        width: 100% !important;
        margin: 0 auto !important;
        padding: 0 24px !important;
        background-color: #ffffff !important;
        min-height: 100vh !important;
        box-shadow: 0 0 10px rgba(0,0,0,0.05) !important; /* è½»å¾®é˜´å½±å¢å¼ºå±‚æ¬¡æ„Ÿ */
    }

    /* 4. å¤´éƒ¨åŒºåŸŸ - legalontech æç®€é£æ ¼ */
    .header-wrapper {
        padding: 32px 0 24px 0 !important;
        border-bottom: 1px solid #eaeaea !important; /* ç»†åˆ†éš”çº¿ */
        margin-bottom: 24px !important;
    }
    .page-title {
        font-size: 2rem !important;
        font-weight: 700 !important;
        color: #222222 !important; /* æ·±ç°æ–‡å­— */
        margin: 0 0 8px 0 !important;
        line-height: 1.3 !important;
    }
    .subtitle {
        font-size: 1rem !important;
        color: #666666 !important;
        margin: 0 !important;
        font-weight: 400 !important;
    }

    /* 5. èŠå¤©æ¶ˆæ¯æ°”æ³¡ - ä¸“ä¸šç®€æ´é£æ ¼ */
    [data-testid="stChatMessage"] {
        margin-bottom: 16px !important;
        padding: 0 !important;
        max-width: 100% !important;
    }
    [data-testid="stChatMessage"][data-role="user"] > div:nth-child(2) {
        background-color: #2d3748 !important; /* æ·±è‰²ä¸“ä¸šè“ */
        color: white !important;
        border-radius: 8px !important;
        padding: 16px 20px !important;
        box-shadow: none !important;
        margin-left: 0 !important;
        font-size: 1rem !important;
        line-height: 1.6 !important;
    }
    [data-testid="stChatMessage"][data-role="assistant"] > div:nth-child(2) {
        background-color: #ffffff !important;
        border: 1px solid #eaeaea !important;
        border-radius: 8px !important;
        padding: 16px 20px !important;
        box-shadow: none !important;
        margin-right: 0 !important;
        font-size: 1rem !important;
        line-height: 1.6 !important;
        color: #333333 !important;
    }
    [data-testid="stChatMessage"] img {
        width: 36px !important;
        height: 36px !important;
        border-radius: 50% !important;
        object-fit: cover !important;
    }

    /* 6. å¸¸è§é—®é¢˜æŒ‰é’® - legalontech æ‰å¹³é£æ ¼ */
    .faq-section {
        margin: 24px 0 32px 0 !important;
    }
    .faq-header {
        font-size: 1.1rem !important;
        font-weight: 600 !important;
        color: #222222 !important;
        margin: 0 0 16px 0 !important;
    }
    .faq-buttons {
        display: grid !important;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)) !important;
        gap: 12px !important;
    }
    div.stButton > button {
        background-color: #ffffff !important;
        color: #333333 !important;
        border: 1px solid #eaeaea !important;
        border-radius: 8px !important;
        font-weight: 500 !important;
        font-size: 1rem !important;
        padding: 14px 18px !important;
        width: 100% !important;
        transition: all 0.2s ease !important;
        box-shadow: none !important;
        text-align: left !important;
    }
    div.stButton > button:hover {
        background-color: #f5f5f5 !important;
        color: #2d3748 !important;
        border-color: #ddd !important;
    }

    /* 7. åº•éƒ¨è¾“å…¥æ¡† - legalontech å›ºå®šåº•éƒ¨æ ·å¼ */
    [data-testid="stChatInput"] {
        position: fixed !important;
        bottom: 0 !important;
        left: 0 !important;
        right: 0 !important;
        background: white !important;
        padding: 16px 0 !important;
        box-shadow: 0 -1px 5px rgba(0,0,0,0.05) !important;
        z-index: 999 !important;
        max-width: 900px !important;
        margin: 0 auto !important;
        width: 100% !important;
        border-top: 1px solid #eaeaea !important;
    }
    [data-testid="stChatInput"] textarea {
        border-radius: 8px !important;
        border: 1px solid #eaeaea !important;
        padding: 16px 20px !important;
        font-size: 1rem !important;
        background-color: #ffffff !important;
        box-shadow: none !important;
        height: 64px !important;
        resize: none !important;
    }
    [data-testid="stChatInput"] textarea:focus {
        border-color: #2d3748 !important;
        background-color: white !important;
        box-shadow: 0 0 0 2px rgba(45, 55, 72, 0.1) !important;
        outline: none !important;
    }

    /* 8. æ¨¡å‹ç»“æœå¡ç‰‡ - legalontech ä¸“ä¸šé£æ ¼ */
    .model-results-section {
        margin: 32px 0 !important;
    }
    .model-compare-header {
        font-size: 1.2rem !important;
        font-weight: 600 !important;
        color: #222222 !important;
        margin: 0 0 20px 0 !important;
        padding-bottom: 12px !important;
        border-bottom: 1px solid #eaeaea !important;
    }
    .model-card {
        background-color: #ffffff !important;
        padding: 24px !important;
        border-radius: 8px !important;
        border: 1px solid #eaeaea !important;
        box-shadow: none !important;
        margin-bottom: 20px !important;
    }
    .model-card-header {
        font-size: 1.1rem !important;
        font-weight: 600 !important;
        margin-bottom: 16px !important;
        display: flex !important;
        align-items: center !important;
        color: #222222 !important;
    }
    .gemini-header {
        color: #4285f4 !important;
    }
    .glm-header {
        color: #ff6700 !important;
    }
    .model-card-content {
        font-size: 1rem !important;
        line-height: 1.7 !important;
        color: #333333 !important;
        white-space: pre-wrap !important;
    }

    /* 9. è¯­ä¹‰æ€»ç»“å¡ç‰‡ - legalontech å¼ºè°ƒé£æ ¼ */
    .semantic-section {
        margin: 32px 0 80px 0 !important; /* åº•éƒ¨ç•™ç©ºé¿å…è¢«è¾“å…¥æ¡†é®æŒ¡ */
    }
    .semantic-compare-header {
        font-size: 1.2rem !important;
        font-weight: 600 !important;
        color: #222222 !important;
        margin: 0 0 20px 0 !important;
        padding-bottom: 12px !important;
        border-bottom: 1px solid #eaeaea !important;
    }
    .semantic-card {
        background-color: #f8f9fa !important;
        padding: 24px !important;
        border-radius: 8px !important;
        border-left: 4px solid #2d3748 !important; /* å·¦ä¾§å¼ºè°ƒçº¿ */
        box-shadow: none !important;
    }
    .semantic-content {
        color: #333333 !important;
        line-height: 1.7 !important;
        font-size: 1rem !important;
    }
    
    /* Markdown æ¸²æŸ“æ ·å¼ - legalontech ä¸“ä¸šé£æ ¼ */
    ul {
        margin: 12px 0 20px 24px !important;
        padding: 0 !important;
    }
    li {
        margin: 8px 0 !important;
        line-height: 1.7 !important;
        color: #333333 !important;
    }
    strong {
        color: #2d3748 !important;
        font-weight: 600 !important;
    }
    p {
        margin: 10px 0 !important;
        padding: 0 !important;
    }

    /* 10. æ¸…ç©ºæŒ‰é’® - æ¬¡è¦æŒ‰é’®é£æ ¼ */
    .clear-btn-wrapper {
        margin: 24px 0 0 0 !important;
    }
    .clear-btn {
        background-color: #ffffff !important;
        color: #666666 !important;
        border: 1px solid #eaeaea !important;
        border-radius: 8px !important;
        padding: 8px 16px !important;
        font-size: 0.9rem !important;
        transition: all 0.2s ease !important;
    }
    .clear-btn:hover {
        background-color: #f5f5f5 !important;
        color: #2d3748 !important;
    }

    /* 11. åŠ è½½å…‰æ ‡ */
    @keyframes blink {
        0%, 100% { opacity: 1; }
        50% { opacity: 0; }
    }
    .blinking-cursor {
        animation: blink 1s infinite;
        margin-left: 4px;
    }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------
# --- å·¥å…·å‡½æ•°ï¼šç»Ÿä¸€æ ¼å¼å¤„ç† + Markdown æ¸²æŸ“ ---
# -------------------------------------------------------------
def clean_extra_newlines(text):
    """æ¸…ç†å†—ä½™æ¢è¡Œ/ç©ºæ ¼"""
    cleaned = re.sub(r'\n{2,}', '\n', text)
    cleaned = re.sub(r'ã€€+', '', cleaned)
    cleaned = re.sub(r'\t+', '', cleaned)
    cleaned = cleaned.strip('\n')
    cleaned = re.sub(r'\n+(- )', '\n- ', cleaned)
    return cleaned

def complete_markdown_syntax(text):
    """è¡¥å…¨æœªé—­åˆçš„ Markdown è¯­æ³•"""
    # è¡¥å…¨åŠ ç²— **
    bold_count = text.count("**")
    if bold_count % 2 != 0:
        text += "**"
    # è¡¥å…¨ä»£ç å— `
    code_count = text.count("`")
    if code_count % 2 != 0:
        text += "`"
    # è¡¥å…¨åˆ—è¡¨
    if text.endswith("- "):
        text += "æœªå®Œæˆçš„è¦ç‚¹"
    return text

def standardize_model_output(text, model_name):
    """
    ç»Ÿä¸€æ¨¡å‹è¾“å‡ºæ ¼å¼ä¸ºæ ‡å‡†åŒ–ç»“æ„
    é€‚é…è¯­ä¹‰åˆ†æçš„æ ¼å¼ï¼šæ ¸å¿ƒè§‚ç‚¹ â†’ åˆ†æè§’åº¦ â†’ å…·ä½“å»ºè®®
    """
    # æ¸…ç†åŸºç¡€æ ¼å¼
    text = clean_extra_newlines(text)
    text = complete_markdown_syntax(text)
    
    # æ ‡å‡†åŒ–è¾“å‡ºç»“æ„
    standardized = f"""**æ ¸å¿ƒè§‚ç‚¹**
{text if text else 'æš‚æ— æœ‰æ•ˆåˆ†æå†…å®¹'}

**åˆ†æè§’åº¦**
- {model_name}ï¼šèšç„¦å¾·å›½è´¢ç¨æ³•è§„çš„{'æ¡æ–‡è§£è¯»' if model_name == 'Gemini' else 'å®æ“è½åœ°'}ç»´åº¦
- åˆ†ææ¡†æ¶ï¼šåŸºäºå¾·å›½ã€Šç¨æ”¶é€šåˆ™ã€‹(AO) å’Œã€Šå¢å€¼ç¨æ³•ã€‹(UStG) ç­‰æ ¸å¿ƒæ³•è§„

**å…·ä½“å»ºè®®**
- å»ºè®®ç»“åˆä¸“ä¸šç¨åŠ¡å¸ˆè¿›è¡Œä¸ªæ€§åŒ–æ–¹æ¡ˆåˆ¶å®š
- ç¡®ä¿æ‰€æœ‰æ“ä½œç¬¦åˆå¾·å›½åé¿ç¨è§„åˆ™å’Œæ¬§ç›Ÿç›¸å…³æŒ‡ä»¤"""
    
    return standardized

def markdown_to_html(text):
    """å°† Markdown è½¬ä¸ºå¯æ¸²æŸ“çš„ HTMLï¼Œé€‚é…æ ‡å‡†åŒ–æ ¼å¼"""
    text = complete_markdown_syntax(text)
    # æ›¿æ¢åŠ ç²—
    text = text.replace("**", "<strong>")
    # å¤„ç†åˆ—è¡¨
    lines = text.split("\n")
    html_lines = []
    in_list = False
    for line in lines:
        line = line.strip()
        if line.startswith("- "):
            if not in_list:
                html_lines.append("<ul>")
                in_list = True
            item = line[2:].strip()
            html_lines.append(f"<li>{item}</li>")
        else:
            if in_list:
                html_lines.append("</ul>")
                in_list = False
            if line.startswith("**") and line.endswith("**"):
                html_lines.append(f"<p><strong>{line.strip('**')}</strong></p>")
            elif line:
                html_lines.append(f"<p>{line}</p>")
    if in_list:
        html_lines.append("</ul>")
    # æ¸…ç†ç©ºæ ‡ç­¾
    html = "\n".join(html_lines).replace("<p></p>", "").replace("<ul></ul>", "")
    return html

# -------------------------------------------------------------
# --- 1. å¸¸é‡å®šä¹‰ä¸åŸºç¡€é…ç½® ---
# -------------------------------------------------------------
USER_ICON = "ğŸ‘¤"
ASSISTANT_ICON = "âš–ï¸"
GEMINI_ICON = "â™Šï¸"
GLM_ICON = "ğŸ§ "

COMMON_LEGAL_QUESTIONS = [
    "æ€ä¹ˆåº”å¯¹ç¨åŠ¡ç¨½æŸ¥ï¼Ÿ",
    "è´§ç‰©å‡ºå£å¾·å›½å¦‚ä½•åˆ¤æ–­å¢å€¼ç¨åœ°ç‚¹ï¼Ÿ",
    "ä¼ä¸šåœ¨å¾·å›½åšé‡ç»„ï¼Œæ€ä¹ˆåšç¨åŠ¡ä¼˜åŒ–"
]

# æ›´æ–°ç³»ç»ŸæŒ‡ä»¤ï¼Œè¦æ±‚è¾“å‡ºæ ‡å‡†åŒ–æ ¼å¼
SYSTEM_INSTRUCTION = """
è§’è‰²ï¼šå¾·å›½èµ„æ·±ç¨åŠ¡å¸ˆï¼ˆ20å¹´è·¨å¢ƒåˆè§„ç»éªŒï¼‰
æœåŠ¡å¯¹è±¡ï¼šä¸­å›½å‡ºæµ·ä¼ä¸š
è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
**æ ¸å¿ƒè§‚ç‚¹**
- æ ¸å¿ƒç»“è®º1
- æ ¸å¿ƒç»“è®º2

**åˆ†æè§’åº¦**
- æ³•è§„ä¾æ®ï¼šå…·ä½“æ³•æ¡/æŒ‡ä»¤ç¼–å·
- åˆ†æç»´åº¦ï¼šåˆè§„é£é™©/ç¨åŠ¡ä¼˜åŒ–/å®æ“è½åœ°

**å…·ä½“å»ºè®®**
- å¯è½åœ°çš„è¡ŒåŠ¨å»ºè®®1
- å¯è½åœ°çš„è¡ŒåŠ¨å»ºè®®2

å…¶ä»–è¦æ±‚ï¼š
1. åŸºäºå¾·å›½ç°è¡Œæ³•å¾‹æ³•è§„ï¼Œæä¾›ä¸“ä¸šã€ä¸¥è°¨çš„åˆè§„å»ºè®®ï¼›
2. æ³•å¾‹ä¾æ®éœ€æ ‡æ³¨å…·ä½“æ³•æ¡/æ¬§ç›ŸæŒ‡ä»¤ç¼–å·ï¼›
3. æ’ç‰ˆç®€æ´ï¼Œå•ä¸ªæ¢è¡Œåˆ†éš”ï¼Œç¦æ­¢å†—ä½™ç©ºç™½ï¼›
4. å…è´£å£°æ˜ç®€æ˜ï¼ˆä¸è¶…è¿‡50å­—ï¼‰ã€‚
"""

# -------------------------- è®¿é—®è®¡æ•°å™¨ --------------------------
COUNTER_FILE = "visit_stats_qfs.json"

def update_daily_visits():
    try:
        today_str = datetime.date.today().isoformat()
        if "has_counted" in st.session_state:
            if os.path.exists(COUNTER_FILE):
                try:
                    with open(COUNTER_FILE, "r") as f:
                        return json.load(f).get("count", 0)
                except:
                    return 0
            return 0
        data = {"date": today_str, "count": 0}
        if os.path.exists(COUNTER_FILE):
            try:
                with open(COUNTER_FILE, "r") as f:
                    file_data = json.load(f)
                    if file_data.get("date") == today_str:
                        data = file_data
            except:
                pass 
        data["count"] += 1
        with open(COUNTER_FILE, "w") as f:
            json.dump(data, f)
        st.session_state["has_counted"] = True
        return data["count"]
    except Exception as e:
        return 0

daily_visits = update_daily_visits()
visit_text = f"ä»Šæ—¥è®¿é—®: {daily_visits}"

# -------------------------------------------------------------
# --- 2. æµå¼è¾“å‡ºæ ¸å¿ƒå‡½æ•° ---
# -------------------------------------------------------------
def stream_gemini_response(prompt, model):
    try:
        stream = model.generate_content(prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.04)
    except Exception as e:
        yield f"\n\nâš ï¸ Geminiè°ƒç”¨å¤±è´¥ï¼š{str(e)[:100]}..."

def stream_glm_response(prompt, api_key, model_name="glm-4"):
    if not api_key:
        yield "âš ï¸ æœªé…ç½®æ™ºè°±GLM API Keyï¼Œæš‚æ— æ³•è·å–è¯¥æ¨¡å‹åˆ†æç»“æœã€‚"
        return
    try:
        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        full_prompt = f"""{SYSTEM_INSTRUCTION}
ç”¨æˆ·é—®é¢˜ï¼š{prompt}
é¢å¤–è¦æ±‚ï¼šä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ ¼å¼è¾“å‡ºï¼Œç»“æ„æ¸…æ™°ï¼Œæ’ç‰ˆç®€æ´ã€‚"""
        data = {
            "model": model_name,
            "messages": [{"role": "user", "content": full_prompt}],
            "temperature": 0.1,
            "max_tokens": 4096,
            "stream": True
        }
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=30)
        response.raise_for_status()
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                    if line == '[DONE]':
                        break
                    try:
                        chunk = json.loads(line)
                        if chunk.get('choices') and chunk['choices'][0].get('delta', {}).get('content'):
                            content = chunk['choices'][0]['delta']['content']
                            yield content
                            time.sleep(0.04)
                    except:
                        continue
    except requests.exceptions.RequestException as e:
        yield f"\n\nâš ï¸ æ™ºè°±GLMè°ƒç”¨å¤±è´¥ï¼š{str(e)[:100]}..."
    except Exception as e:
        yield f"\n\nâš ï¸ æ™ºè°±GLMå¤„ç†å¤±è´¥ï¼š{str(e)[:100]}..."

def generate_semantic_compare(gemini_resp, glm_resp, user_question, gemini_api_key):
    """ç”Ÿæˆæ ‡å‡†åŒ–æ ¼å¼çš„è¯­ä¹‰å¯¹æ¯”åˆ†æ"""
    compare_prompt = f"""
ä½œä¸ºå¾·å›½è´¢ç¨åˆ†æä¸“å®¶ï¼Œå¯¹æ¯”ä»¥ä¸‹ä¸¤ä¸ªæ¨¡å‹é’ˆå¯¹"{user_question}"çš„å›ç­”ï¼ŒæŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ€»ç»“è¯­ä¹‰å¼‚åŒï¼š

### è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
**æ ¸å¿ƒå…±è¯†**
- è¦ç‚¹1
- è¦ç‚¹2
- è¦ç‚¹3

**è§‚ç‚¹å·®å¼‚**
- Geminiï¼šåˆ†æè§’åº¦å’Œä¾§é‡ç‚¹
- æ™ºè°±GLMï¼šåˆ†æè§’åº¦å’Œä¾§é‡ç‚¹

**ç»¼åˆå»ºè®®**
å…·ä½“ã€å¯è½åœ°çš„è¡ŒåŠ¨å»ºè®®ï¼ˆä¸å°‘äº80å­—ï¼‰

### Geminiå›ç­”ï¼š
{gemini_resp[:2000]}

### æ™ºè°±GLMå›ç­”ï¼š
{glm_resp[:2000]}

### è¦æ±‚ï¼š
1. æ ¸å¿ƒå…±è¯†æå–3-4æ¡æ ¸å¿ƒè§‚ç‚¹å…±è¯†
2. è§‚ç‚¹å·®å¼‚æ¸…æ™°å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„åˆ†æè§’åº¦
3. ç»¼åˆå»ºè®®éœ€ç»“åˆå¾·å›½å…·ä½“æ³•è§„å’Œå®æ“åœºæ™¯
4. æ’ç‰ˆç®€æ´ï¼Œæ— å†—ä½™ç©ºç™½ï¼Œä¸“ä¸šä¸¥è°¨
"""
    try:
        genai.configure(api_key=gemini_api_key)
        summary_model = genai.GenerativeModel(
            model_name='gemini-flash-latest',
            generation_config={
                "temperature": 0.1, 
                "max_output_tokens": 3000,
                "top_p": 0.95
            }
        )
        stream = summary_model.generate_content(compare_prompt, stream=True)
        for chunk in stream:
            if chunk.text:
                yield chunk.text
                time.sleep(0.03)
    except Exception as e:
        st.error(f"è¯­ä¹‰æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        print(f"è¯­ä¹‰æ€»ç»“é”™è¯¯è¯¦æƒ…ï¼š{e}")
        yield f"""
**æ ¸å¿ƒå…±è¯†**
- å‡è®¤å¯{user_question}ç›¸å…³å¾·å›½è´¢ç¨æ³•è§„çš„æ ¸å¿ƒé€‚ç”¨åŸåˆ™
- å‡å¼ºè°ƒåˆè§„æ“ä½œå’Œé£é™©é˜²æ§çš„å¿…è¦æ€§
- å‡å»ºè®®ç»“åˆä¸“ä¸šç¨åŠ¡å¸ˆå’¨è¯¢è½åœ°
- å‡éœ€éµå®ˆå¾·å›½åé¿ç¨è§„åˆ™å’Œæ¬§ç›ŸATADæŒ‡ä»¤

**è§‚ç‚¹å·®å¼‚**
- Geminiï¼šä¾§é‡æ³•æ¡å­—é¢è§£è¯»ã€å›½é™…é€šç”¨æ€§å’Œåˆè§„æ¡†æ¶æ­å»ºï¼Œå…³æ³¨æ¬§ç›Ÿå±‚é¢çš„åè°ƒè§„åˆ™
- æ™ºè°±GLMï¼šä¾§é‡ä¸­ä¼å®æ“è½åœ°ã€æœ¬åœŸåŒ–é€‚é…å’Œæµç¨‹ç®€åŒ–ï¼Œå…³æ³¨å…·ä½“ç”³æŠ¥æµç¨‹å’Œææ–™å‡†å¤‡

**ç»¼åˆå»ºè®®**
é’ˆå¯¹{user_question}ï¼Œå»ºè®®å…ˆå‚è€ƒGeminiçš„åˆè§„æ¡†æ¶ç¡®ä¿ç¬¦åˆå¾·å›½ã€Šç¨æ”¶é€šåˆ™ã€‹(AO)å’Œã€Šå¢å€¼ç¨æ³•ã€‹(UStG)ç­‰æ ¸å¿ƒæ³•è§„è¦æ±‚ï¼Œå†ç»“åˆæ™ºè°±GLMçš„å®æ“å»ºè®®ä¼˜åŒ–è½åœ°æµç¨‹ã€‚å…³é”®èŠ‚ç‚¹éœ€å’¨è¯¢å¾·å›½å½“åœ°ç¨åŠ¡å¸ˆï¼Œç¡®ä¿è½¬è®©å®šä»·ç¬¦åˆBEPSè§„åˆ™ï¼ŒåŒæ—¶åšå¥½ç¨åŠ¡ç¨½æŸ¥çš„æ–‡æ¡£å‡†å¤‡å·¥ä½œï¼Œé™ä½åˆè§„é£é™©ã€‚
"""

# -------------------------------------------------------------
# --- 3. æ¨¡å‹åˆå§‹åŒ–ä¸ä¼šè¯çŠ¶æ€ ---
# -------------------------------------------------------------
gemini_api_key = st.secrets.get("GEMINI_API_KEY", "")
glm_api_key = st.secrets.get("GLM_API_KEY", "")

# å®¹é”™æç¤ºï¼ˆlegalontech é£æ ¼ï¼‰
if not gemini_api_key:
    st.markdown(f"""
    <div style="
        background-color: #fff5f5; 
        color: #c53030; 
        padding: 16px 20px; 
        border-radius: 8px; 
        margin: 24px 0;
        font-size: 1rem;
        border-left: 4px solid #e53e3e;
    ">
        âš ï¸ æœªé…ç½®Gemini API Key<br>
        è¯·åœ¨ /workspaces/qfs/.streamlit/secrets.toml ä¸­æ·»åŠ ï¼š<br>
        <code style="font-size: 0.9rem; background-color: #fef2f2; padding: 2px 6px; border-radius: 4px;">GEMINI_API_KEY = "ä½ çš„Geminiå¯†é’¥"</code>
    </div>
    """, unsafe_allow_html=True)
    st.session_state["api_configured"] = False
else:
    st.session_state["api_configured"] = True

@st.cache_resource(show_spinner="æ­£åœ¨åŠ è½½ä¸“ä¸šçŸ¥è¯†åº“...")
def initialize_gemini_model():
    if not gemini_api_key:
        return None
    generation_config = {
        "max_output_tokens": 4096,
        "temperature": 0.1,
        "top_p": 0.95
    }
    model = genai.GenerativeModel(
        model_name='gemini-flash-latest', 
        system_instruction=SYSTEM_INSTRUCTION,
        generation_config=generation_config
    )
    return model

gemini_model = initialize_gemini_model()

# ä¼šè¯çŠ¶æ€åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¾·å›½è´¢ç¨ä¸“å®¶QFSã€‚è¯·é—®æ‚¨åœ¨ä¸­å›½ä¼ä¸šå‡ºæµ·è¿‡ç¨‹ä¸­é‡åˆ°äº†å“ªäº›è´¢åŠ¡ã€ç¨åŠ¡æˆ–å•†ä¸šèµ„è´¨æ–¹é¢çš„é—®é¢˜ï¼Ÿ"}
    ]
if "model_responses" not in st.session_state:
    st.session_state.model_responses = {}

# -------------------------------------------------------------
# --- 4. ä¸»ç¨‹åºå…¥å£ (legalontech é£æ ¼å¸ƒå±€) ---
# -------------------------------------------------------------
st.markdown('<div class="main-container">', unsafe_allow_html=True)

# å¤´éƒ¨åŒºåŸŸï¼ˆlegalontech é£æ ¼ï¼‰
st.markdown("""
<div class="header-wrapper">
    <h1 class="page-title">ğŸ‡©ğŸ‡ª å¾·å›½è´¢ç¨åˆè§„ä¸“å®¶</h1>
    <p class="subtitle">ä¸“æ³¨ä¸­å›½ä¼ä¸šå‡ºæµ·å¾·å›½çš„ç¨åŠ¡åˆè§„ä¸ä¼˜åŒ–</p>
</div>
""", unsafe_allow_html=True)

# å¸¸è§é—®é¢˜åŒºåŸŸ
st.markdown("""
<div class="faq-section">
    <h2 class="faq-header">ğŸ’¡ å¸¸è§é—®é¢˜å¿«é€ŸæŸ¥è¯¢</h2>
    <div class="faq-buttons">
""", unsafe_allow_html=True)

prompt_from_button = None
cols = st.columns(1)
with cols[0]:
    for i, question in enumerate(COMMON_LEGAL_QUESTIONS):
        if st.button(question, key=f"q_{i}"):
            prompt_from_button = question

st.markdown("""
    </div>
</div>
""", unsafe_allow_html=True)

# èŠå¤©åŒºåŸŸ
for msg in st.session_state.messages:
    icon = USER_ICON if msg["role"] == "user" else ASSISTANT_ICON
    st.chat_message(msg["role"], avatar=icon).write(msg["content"])

# è·å–ç”¨æˆ·è¾“å…¥
chat_input_text = st.chat_input("è¯·è¾“å…¥ä½ çš„åˆè§„é—®é¢˜...")
user_input = prompt_from_button if prompt_from_button else chat_input_text

# å¤„ç†ç”¨æˆ·è¾“å…¥
if user_input and st.session_state.get("api_configured", False):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user", avatar=USER_ICON).write(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # === 1. Gemini æµå¼è¾“å‡ºï¼ˆæ ‡å‡†åŒ–æ ¼å¼ï¼‰ ===
    st.markdown("""
    <div class="model-results-section">
        <h2 class="model-compare-header">ğŸ” æ¨¡å‹åˆ†æç»“æœ</h2>
    """, unsafe_allow_html=True)
    
    # Gemini å¡ç‰‡
    st.markdown(f"""
    <div class="model-card">
        <div class="model-card-header gemini-header">
            {GEMINI_ICON} Gemini Flash åˆ†æç»“æœ
        </div>
        <div class="model-card-content" id="gemini-content">
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    gemini_placeholder = st.empty()
    gemini_full_response = ""
    for chunk in stream_gemini_response(user_input, gemini_model):
        gemini_full_response += chunk
        # æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼
        standardized_gemini = standardize_model_output(gemini_full_response, "Gemini")
        cleaned_gemini = clean_extra_newlines(standardized_gemini)
        display_gemini = markdown_to_html(cleaned_gemini)
        
        gemini_placeholder.markdown(f"""
        <div class="model-card">
            <div class="model-card-header gemini-header">
                {GEMINI_ICON} Gemini Flash åˆ†æç»“æœ
            </div>
            <div class="model-card-content">
                {display_gemini}<span class="blinking-cursor">|</span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“ Geminiï¼ˆæ ‡å‡†åŒ–æ ¼å¼ï¼‰
    final_gemini = standardize_model_output(gemini_full_response, "Gemini")
    final_display_gemini = markdown_to_html(final_gemini)
    gemini_placeholder.markdown(f"""
    <div class="model-card">
        <div class="model-card-header gemini-header">
            {GEMINI_ICON} Gemini Flash åˆ†æç»“æœ
        </div>
        <div class="model-card-content">
            {final_display_gemini}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # === 2. æ™ºè°± GLM æµå¼è¾“å‡ºï¼ˆæ ‡å‡†åŒ–æ ¼å¼ï¼‰ ===
    st.markdown(f"""
    <div class="model-card">
        <div class="model-card-header glm-header">
            {GLM_ICON} æ™ºè°±GLM-4 åˆ†æç»“æœ
        </div>
        <div class="model-card-content" id="glm-content">
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    glm_placeholder = st.empty()
    glm_full_response = ""
    for chunk in stream_glm_response(user_input, glm_api_key):
        glm_full_response += chunk
        # æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼
        standardized_glm = standardize_model_output(glm_full_response, "æ™ºè°±GLM")
        cleaned_glm = clean_extra_newlines(standardized_glm)
        display_glm = markdown_to_html(cleaned_glm)
        
        glm_placeholder.markdown(f"""
        <div class="model-card">
            <div class="model-card-header glm-header">
                {GLM_ICON} æ™ºè°±GLM-4 åˆ†æç»“æœ
            </div>
            <div class="model-card-content">
                {display_glm}<span class="blinking-cursor">|</span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“ GLMï¼ˆæ ‡å‡†åŒ–æ ¼å¼ï¼‰
    final_glm = standardize_model_output(glm_full_response, "æ™ºè°±GLM")
    final_display_glm = markdown_to_html(final_glm)
    glm_placeholder.markdown(f"""
    <div class="model-card">
        <div class="model-card-header glm-header">
            {GLM_ICON} æ™ºè°±GLM-4 åˆ†æç»“æœ
        </div>
        <div class="model-card-content">
            {final_display_glm}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)  # å…³é—­ model-results-section
    
    # å­˜å‚¨ç»“æœ
    st.session_state.model_responses[user_input] = {
        "gemini": gemini_full_response,
        "glm": glm_full_response
    }
    
    # === 3. è¯­ä¹‰å¯¹æ¯”åˆ†æï¼ˆæ ‡å‡†åŒ–æ ¼å¼ï¼‰ ===
    st.markdown("""
    <div class="semantic-section">
        <h2 class="semantic-compare-header">ğŸ“Š è¯­ä¹‰å±‚é¢å¼‚åŒåˆ†æ</h2>
    """, unsafe_allow_html=True)
    
    semantic_placeholder = st.empty()
    semantic_full_response = ""
    
    for chunk in generate_semantic_compare(gemini_full_response, glm_full_response, user_input, gemini_api_key):
        semantic_full_response += chunk
        cleaned_semantic = clean_extra_newlines(semantic_full_response)
        display_semantic = markdown_to_html(cleaned_semantic)
        
        semantic_placeholder.markdown(f"""
        <div class="semantic-card">
            <div class="semantic-content">
                {display_semantic}<span class="blinking-cursor">|</span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ç»ˆæ¸²æŸ“è¯­ä¹‰æ€»ç»“
    final_semantic = clean_extra_newlines(semantic_full_response)
    final_display_semantic = markdown_to_html(final_semantic)
    semantic_placeholder.markdown(f"""
    <div class="semantic-card">
        <div class="semantic-content">
            {final_display_semantic}
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)  # å…³é—­ semantic-section
    
    # æ·»åŠ åˆ°èŠå¤©è®°å½•
    combined_response = f"""
### åŒæ¨¡å‹è¯­ä¹‰åˆ†ææ€»ç»“ï¼š
{final_semantic}

### å®Œæ•´åˆ†æå‚è€ƒï¼š
- Gemini ä¾§é‡å¾·å›½è´¢ç¨æ³•è§„çš„æ¡æ–‡è§£è¯»å’Œå›½é™…é€šç”¨æ€§
- æ™ºè°±GLM ä¾§é‡ä¸­ä¼å‡ºæµ·çš„å®æ“è½åœ°å’Œæœ¬åœŸåŒ–é€‚é…
    """
    st.session_state.messages.append({"role": "assistant", "content": combined_response})

# æ¸…ç©ºæŒ‰é’®
st.markdown('<div class="clear-btn-wrapper">', unsafe_allow_html=True)
def clear_chat_history():
    st.session_state.messages = [
        {"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¾·å›½è´¢ç¨ä¸“å®¶QFSã€‚è¯·é—®æ‚¨åœ¨ä¸­å›½ä¼ä¸šå‡ºæµ·è¿‡ç¨‹ä¸­é‡åˆ°äº†å“ªäº›è´¢åŠ¡ã€ç¨åŠ¡æˆ–å•†ä¸šèµ„è´¨æ–¹é¢çš„é—®é¢˜ï¼Ÿ"}
    ]
    st.session_state.model_responses = {}

st.button(
    'ğŸ§¹ æ¸…ç©ºèŠå¤©è®°å½•', 
    help="æ¸…é™¤æ‰€æœ‰å†å²å¯¹è¯", 
    key="clear_btn",
    on_click=clear_chat_history,
    
)
st.markdown('</div>', unsafe_allow_html=True)

# é—­åˆä¸»å®¹å™¨
st.markdown('</div>', unsafe_allow_html=True)
